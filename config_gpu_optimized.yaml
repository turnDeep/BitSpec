# config_gpu_optimized.yaml
# NEIMS v2.0 GPU最適化設定ファイル
# RTX 40/50シリーズ向けの最大性能設定

# このファイルはGPUリソースを最大限活用するための設定です
# 使用方法: python scripts/train_pipeline.py --config config_gpu_optimized.yaml

# ベース設定を継承
# 主な変更点:
# - バッチサイズの最適化（GPUメモリに応じて）
# - PyTorch 2.0+ の最適化機能を活用
# - cuDNN/TensorFloat-32の有効化
# - データローダーの並列化

# プロジェクト設定
project:
  name: "NEIMS_v2_GPU_Optimized"
  description: "GPU最適化版 - RTX 40/50シリーズ向け"
  version: "2.0.0"

# データ設定
data:
  nist_msp_path: "data/NIST17.msp"
  mol_files_dir: "data/mol_files"
  pcqm4mv2_path: "data/pcqm4mv2"
  massbank_path: "data/massbank"
  gnps_path: "data/gnps"
  output_dir: "data/processed"

  train_split: 0.8
  val_split: 0.1
  test_split: 0.1

  max_mz: 500
  mz_bin_size: 1.0
  min_intensity: 0.001

  # メモリ効率モード（GPUメモリが潤沢な場合は無効化可能）
  memory_efficient_mode:
    enabled: false                             # GPU最適化版では無効化
    use_lazy_loading: false                    # 高速化のため事前計算
    precompute_graphs: true                    # グラフを事前計算（速度優先）

# モデル設定（より大きなモデル）
model:
  teacher:
    type: "GNN_ECFP_Hybrid"
    gnn:
      conv_type: "GINEConv"
      num_layers: 10                           # より深いネットワーク（8→10）
      hidden_dim: 384                          # より大きな隠れ層（256→384）
      edge_dim: 192                            # エッジ特徴量も増加（128→192）
      dropout: 0.3
      drop_edge: 0.2
      use_pair_norm: true
      use_bond_breaking: true

    ecfp:
      fingerprint_size: 4096
      mlp_hidden: 1536                         # より大きなMLP（1024→1536）
      mlp_output: 768                          # 出力次元も増加（512→768）
      dropout: 0.3

    fusion_dim: 1920                           # GNN(1152) + ECFP(768)

    prediction:
      hidden_dims: [1536, 768]                 # より大きな予測ヘッド
      output_dim: 501
      use_bidirectional: true

    mc_dropout:
      n_samples: 30
      dropout_rate: 0.3

  student:
    type: "MoE_Residual"
    input_dim: 6144
    gate:
      hidden_dims: [768, 256]                  # より大きなゲート（512,128→768,256）
      num_experts: 8                           # エキスパート数増加（4→8）
      top_k: 3                                 # Top-K増加（2→3）

    experts:
      num_experts: 8                           # エキスパート数増加
      residual_blocks_per_expert: 8            # ブロック数増加（6→8）
      hidden_dim: 8192                         # より大きな隠れ層（6144→8192）
      activation: "gelu"
      use_layer_norm: true

    prediction:
      hidden_dims: [3072, 1536]                # より大きな予測ヘッド
      output_dim: 501
      dropout: 0.2
      use_bidirectional: true

  common:
    spectrum_dim: 501
    node_features: 48
    edge_features: 6

# 訓練設定（GPU最適化）
training:
  # Phase 1: Teacher事前学習（PCQM4Mv2）
  teacher_pretrain:
    dataset: "PCQM4Mv2"
    task: "bond_masking"

    # GPUメモリ別のバッチサイズ推奨値:
    # 16GB (RTX 4060 Ti, RTX 5070 Ti): batch_size: 128
    # 24GB (RTX 4090, RTX 5080): batch_size: 256
    # 32GB+ (RTX 5090): batch_size: 512
    batch_size: 256                            # 24GBの場合（要調整）

    num_epochs: 50
    num_workers: 12                            # CPUコア数に応じて調整（8→12）
    prefetch_factor: 6                         # プリフェッチを増加（4→6）
    persistent_workers: true                   # Workerを再利用

    learning_rate: 1.0e-4
    weight_decay: 1.0e-5
    optimizer: "AdamW"
    scheduler: "CosineAnnealingWarmRestarts"
    scheduler_t0: 10
    scheduler_tmult: 2
    gradient_clip: 1.0
    use_amp: true

    checkpoint_dir: "checkpoints/teacher"
    save_interval: 10

  # Phase 2: Teacherファインチューニング（NIST EI-MS）
  teacher_finetune:
    dataset: "NIST_EIMS"
    batch_size: 64                             # MC Dropout用（32→64）
    num_epochs: 100
    num_workers: 12
    prefetch_factor: 6
    persistent_workers: true

    learning_rate: 1.0e-4
    weight_decay: 1.0e-5
    optimizer: "AdamW"
    scheduler: "CosineAnnealingWarmRestarts"
    scheduler_t0: 10
    scheduler_tmult: 2
    gradient_clip: 1.0
    use_amp: true
    mc_dropout_samples: 30

    checkpoint_dir: "checkpoints/teacher"
    save_interval: 5
    pretrained_checkpoint: "checkpoints/teacher/pretrained_teacher.pt"

  # Phase 3: Student知識蒸留
  student_distill:
    dataset: "NIST_EIMS"
    batch_size: 64                             # より大きなバッチ（32→64）
    num_epochs: 150
    num_workers: 12
    prefetch_factor: 6
    persistent_workers: true

    learning_rate: 5.0e-4
    weight_decay: 1.0e-4
    optimizer: "AdamW"
    scheduler: "OneCycleLR"
    max_lr: 1.0e-3
    pct_start: 0.1
    gradient_clip: 0.5
    use_amp: true

    checkpoint_dir: "checkpoints/student"
    save_interval: 5
    teacher_checkpoint: "checkpoints/teacher/finetuned_teacher.pt"

    distillation:
      temperature_init: 4.0
      temperature_min: 1.0
      temperature_schedule: "cosine"
      alpha_init: 0.3
      beta_init: 0.5
      gamma_init: 0.2
      delta_load: 0.01
      delta_entropy: 0.001
      use_gradnorm: true
      warmup_epochs: 15
      gradient_clip_range: [0.5, 2.0]
      use_lds: true
      lds_sigma: 1.5

  common:
    use_wandb: false
    wandb_project: "neims-v2-gpu-optimized"
    log_interval: 10
    val_interval: 1
    early_stopping:
      patience: 20
      min_delta: 0.0001

# GPU設定（最大性能）
gpu:
  use_cuda: true
  device_ids: [0]                              # 複数GPU: [0, 1, 2, 3]
  mixed_precision: true

  # PyTorch 2.0+ コンパイルモード
  compile: false                               # PyTorch Geometricとの互換性のため無効
  compile_mode: "max-autotune"                 # 有効化する場合は最大最適化

  # メモリ最適化
  memory_optimization:
    gradient_accumulation_steps: 1             # GPUメモリ不足時は2-4に増やす
    empty_cache_interval: 200                  # キャッシュクリア頻度を下げる（100→200）
    pin_memory: true
    non_blocking: true                         # 非同期転送を有効化

  # cuDNN最適化
  cudnn:
    benchmark: true                            # 最速のアルゴリズムを自動選択
    deterministic: false                       # 再現性より速度優先
    allow_tf32: true                           # TensorFloat-32を有効化（Ampere+）

  # CUDA最適化
  cuda:
    matmul_allow_tf32: true                    # 行列演算でTF32を使用
    matmul_precision: "high"                   # "high", "medium", "highest"
    flash_attention: true                      # Flash Attentionを有効化（Ampere+）

  # RTX 50シリーズ固有の最適化
  rtx50:
    enable_compat: true
    force_sm90_emulation: false
    enable_fp8: false                          # FP8サポート（実験的、PyTorch 2.7+）

  # 複数GPU設定（オプション）
  multi_gpu:
    enabled: false                             # 複数GPU使用時にtrue
    strategy: "ddp"                            # "ddp" (推奨) or "dp"
    find_unused_parameters: false
    gradient_as_bucket_view: true              # メモリ効率改善

# CPU設定
cpu:
  num_cores: 8                                 # 実際のコア数に調整
  num_threads: 16                              # ハイパースレッディング
  memory_limit_gb: 32

# ロギング設定
logging:
  use_tensorboard: true
  use_wandb: false
  log_dir: "logs/neims_v2_gpu_optimized"
  wandb_project: "neims-v2-gpu-optimized"
  log_every: 10

  # GPU使用状況のロギング
  log_gpu_stats: true                          # GPU使用率、メモリ使用量をログ
  gpu_stats_interval: 100                      # 100ステップごと

# 評価設定
evaluation:
  metrics:
    - "recall_at_k"
    - "spectral_similarity"
    - "mse"
    - "mae"
    - "rmse"
  recall_k_values: [5, 10, 20]
  recall_target: 0.955
  measure_inference_time: true
  measure_memory_usage: true

  # より大きなバッチで評価
  eval_batch_size: 128                         # 評価時のバッチサイズ

  neims_v2_metrics:
    expert_usage: true
    mc_dropout_uncertainty: true
    kd_efficiency: true

# データ拡張
augmentation:
  lds:
    enabled: true
    sigma: 1.5
  isotope:
    enabled: true
    probability: 0.05
    max_substitutions: 2
  conformer:
    enabled: true
    num_conformers: 5

# パフォーマンスプロファイリング（オプション）
profiling:
  enabled: false                               # プロファイリング有効化
  trace_dir: "profiling/traces"                # PyTorch Profilerの出力先
  profile_memory: true
  profile_cuda: true
  profile_schedule:
    wait: 1
    warmup: 1
    active: 3
    repeat: 2

# 環境変数（スクリプトで設定推奨）
# export CUDA_VISIBLE_DEVICES=0,1,2,3
# export TORCH_CUDA_ARCH_LIST="8.9;9.0;12.0"
# export CUDA_CACHE_DISABLE=0
# export CUDA_CACHE_MAXSIZE=2147483648
# export CUDNN_BENCHMARK=1
# export OMP_NUM_THREADS=8
