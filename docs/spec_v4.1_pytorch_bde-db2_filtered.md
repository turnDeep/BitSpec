# QC-GN2oMS2-EI ã‚·ã‚¹ãƒ†ãƒ è©³ç´°æŠ€è¡“ä»•æ§˜æ›¸ v4.1
## PyTorchçµ±ä¸€ç’°å¢ƒãƒ»BonDNet BDE-db2ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç‰ˆï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°è¿½åŠ ï¼‰

**ä½œæˆæ—¥**: 2025-12-02
**å¯¾è±¡ã‚·ã‚¹ãƒ†ãƒ **: NExtIMS (NIST EI-MS Prediction System)
**åŸºç›¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: QC-GN2oMS2 (PNNL)
**ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢**: NVIDIA GeForce RTX 5070 Ti (Blackwell sm_120)

---

## ğŸ“‹ ç›®æ¬¡

1. [ä¸»è¦å¤‰æ›´ç‚¹ï¼ˆv4.0 â†’ v4.1ï¼‰](#ä¸»è¦å¤‰æ›´ç‚¹v40--v41)
2. [ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦](#ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦)
3. [ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ](#ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ)
4. [Phase 0: BDE-db2ç’°å¢ƒæ§‹ç¯‰](#phase-0-bde-db2ç’°å¢ƒæ§‹ç¯‰)
5. [Phase 1: ãƒ‡ãƒ¼ã‚¿æº–å‚™](#phase-1-ãƒ‡ãƒ¼ã‚¿æº–å‚™)
6. [Phase 2: GNNå­¦ç¿’](#phase-2-gnnå­¦ç¿’)
7. [Phase 3: è©•ä¾¡](#phase-3-è©•ä¾¡)
8. [è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°](#è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°)
9. [é–‹ç™ºç’°å¢ƒæ§‹ç¯‰](#é–‹ç™ºç’°å¢ƒæ§‹ç¯‰)
10. [ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³](#ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³)
11. [å‚è€ƒæ–‡çŒ®](#å‚è€ƒæ–‡çŒ®)

---

## ä¸»è¦å¤‰æ›´ç‚¹ï¼ˆv4.0 â†’ v4.1ï¼‰

### âœ… v4.1ã§ã®è¿½åŠ ãƒ»ä¿®æ­£

| é …ç›® | è©³ç´° |
|------|------|
| **ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã®æ˜ç¤ºåŒ–** | Phase 1ã«ã‚µãƒãƒ¼ãƒˆå…ƒç´ ãƒ»åˆ†å­é‡ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¿½åŠ  |
| **ã‚µãƒãƒ¼ãƒˆå…ƒç´ ã®å³å¯†åŒ–** | C, H, O, N, F, S, P, Cl, Br, Iä»¥å¤–ã‚’å«ã‚€åŒ–åˆç‰©ã‚’é™¤å¤–ï¼ˆ-5%ï¼‰ |
| **åˆ†å­é‡ä¸Šé™ã®è¨­å®š** | MW <= 1000 Daã«é™å®šã—ã€å‡ºåŠ›ç¯„å›²ï¼ˆm/z 50-1000ï¼‰ã¨æ•´åˆ |
| **æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚ºã®ä¿®æ­£** | 300,000 â†’ 280,000 spectraï¼ˆ93.3% retentionï¼‰ |
| **äºˆå‚™æ¬¡å…ƒã®æ˜ç¢ºåŒ–** | å°†æ¥ã®æ‹¡å¼µæ€§ã®ãŸã‚ã®è¨­è¨ˆã§ã‚ã‚‹ã“ã¨ã‚’èª¬æ˜ |

### v4.0ã‹ã‚‰ã®ä¸»è¦å¤‰æ›´ï¼ˆç¶™ç¶šï¼‰

| é …ç›® | è©³ç´° |
|------|------|
| **BonDNet BDE-db2ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåŒ–** | 531,244ä»¶ã®BDEãƒ‡ãƒ¼ã‚¿ã§å†å­¦ç¿’ã—ãŸBonDNetã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«è¨­å®š |
| **Pure PyTorchç’°å¢ƒ** | TensorFlowä¾å­˜ã‚’å®Œå…¨å‰Šé™¤ã€‚PyTorch 2.10.0+ nightly (cu128) ã®ã¿ä½¿ç”¨ |
| **Phase 0ã®è¿½åŠ ** | BDE-db2ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰â†’BonDNetå†å­¦ç¿’ã‚’ãƒ‡ãƒ¼ã‚¿æº–å‚™å‰ã®å¿…é ˆãƒ•ã‚§ãƒ¼ã‚ºã¨ã—ã¦è¿½åŠ  |
| **ãƒãƒ­ã‚²ãƒ³ãƒ»ç¡«é»„ãƒ»ãƒªãƒ³å¯¾å¿œ** | BDE-db2ã«ã‚ˆã‚Š10å…ƒç´ ï¼ˆC,H,O,N,F,S,P,Cl,Br,Iï¼‰ã‚’ã‚µãƒãƒ¼ãƒˆ |

---

## ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦

### ç›®çš„

NIST 17 EI-MSãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆç´„280,000ã‚¹ãƒšã‚¯ãƒˆãƒ«ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œï¼‰ã‚’ç”¨ã„ã¦ã€**ç‰©ç†åŒ–å­¦çš„ã«è§£é‡ˆå¯èƒ½ãªGraph Neural Network**ã«ã‚ˆã‚‹EI-MSã‚¹ãƒšã‚¯ãƒˆãƒ«äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

### åŸºç›¤æŠ€è¡“

**QC-GN2oMS2**ï¼ˆPNNL, 2024ï¼‰:
- è«–æ–‡: "Quantum Chemistry-Informed Graph Neural Network for Mass Spectrum Prediction"
- ç‰¹å¾´: é‡å­åŒ–å­¦è¨ˆç®—ï¼ˆBDEï¼‰ã‚’ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã¨ã—ã¦ä½¿ç”¨
- å…ƒã®å¯¾è±¡: MS/MSï¼ˆã‚¿ãƒ³ãƒ‡ãƒ è³ªé‡åˆ†æï¼‰
- **æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã®é©ç”¨**: EI-MSï¼ˆé›»å­ã‚¤ã‚ªãƒ³åŒ–è³ªé‡åˆ†æã€70eVå›ºå®šï¼‰

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦å›³

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 0: BDE-db2ç’°å¢ƒæ§‹ç¯‰ï¼ˆå¿…é ˆå‰å‡¦ç†ï¼‰                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. BDE-db2ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (531,244 reactions)                   â”‚
â”‚ 2. BonDNetå†å­¦ç¿’ (2-3æ—¥, RTX 5070 Ti)                        â”‚
â”‚ 3. å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ (MAE < 1.0 kcal/molç›®æ¨™)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 1: ãƒ‡ãƒ¼ã‚¿æº–å‚™                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1.1 NIST 17èª­ã¿è¾¼ã¿ (300,000 spectra)                       â”‚
â”‚ 1.2 ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° (NEW!)                              â”‚
â”‚     - ã‚µãƒãƒ¼ãƒˆå…ƒç´ ãƒã‚§ãƒƒã‚¯ (C,H,O,N,F,S,P,Cl,Br,I)          â”‚
â”‚     - åˆ†å­é‡ãƒ•ã‚£ãƒ«ã‚¿ (MW <= 1000 Da)                         â”‚
â”‚     â†’ 280,000 spectra (93.3% retention)                     â”‚
â”‚ 1.3 BonDNet BDEè¨ˆç®— (70 min)                                â”‚
â”‚ 1.4 PyG Graphç”Ÿæˆ                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 2: GNNå­¦ç¿’                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 10-layer GATv2Conv + Residual Connections                   â”‚
â”‚ RTX 5070 Ti (16GB GDDR7) Ã— ç´„48æ™‚é–“                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 3: è©•ä¾¡                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Cosine Similarity, Top-10 Recall, Physical Interpretability â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ

### BDEè¨ˆç®—ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰: BonDNet (BDE-db2å†å­¦ç¿’ç‰ˆ)

#### é¸å®šç†ç”±

| åŸºæº– | BonDNet (BDE-db2) | ALFABET | xTB GPU |
|------|------------------|---------|---------|
| **ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯** | PyTorch âœ… | TensorFlow âŒ | Fortran (nvfortran) |
| **é€Ÿåº¦** | 15ms/åˆ†å­ âœ… | 5ms/åˆ†å­ | 1.5ç§’/åˆ†å­ âŒ |
| **ç²¾åº¦** | MAE 0.51 kcal/mol âœ… | MAE 0.45 kcal/mol | MAE 3-5 kcal/mol âŒ |
| **å¯¾å¿œå…ƒç´ ** | 10å…ƒç´  (BDE-db2) âœ… | 6å…ƒç´  | å…¨å…ƒç´  |
| **BDEç›´æ¥è¨ˆç®—** | å¯èƒ½ âœ… | å¯èƒ½ | ä¸å¯ï¼ˆã‚¨ãƒãƒ«ã‚®ãƒ¼å·®åˆ†æ³•ã®ã¿ï¼‰âŒ |
| **ç’°å¢ƒçµ±ä¸€æ€§** | PyTorchçµ±ä¸€ âœ… | TF/PyTorchæ··åœ¨ âŒ | åˆ¥ãƒ—ãƒ­ã‚»ã‚¹èµ·å‹• |
| **å­¦ç¿’ã‚³ã‚¹ãƒˆ** | 2-3æ—¥ (åˆå›ã®ã¿) | å­¦ç¿’æ¸ˆã¿ | N/A |

#### ã‚µãƒãƒ¼ãƒˆå…ƒç´ ï¼ˆ10å…ƒç´ ã€å³å¯†ï¼‰

**C, H, O, N, F, S, P, Cl, Br, I**

**ã“ã‚Œã‚‰ä»¥å¤–ã®å…ƒç´ ã‚’å«ã‚€åŒ–åˆç‰©ã¯å­¦ç¿’ãƒ»è©•ä¾¡ã‹ã‚‰é™¤å¤–**

ç†ç”±:
1. BonDNet BDE-db2ã¯10å…ƒç´ ã§ã®ã¿å­¦ç¿’æ¸ˆã¿
2. ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã®one-hotã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒ10æ¬¡å…ƒï¼ˆ10å…ƒç´ å°‚ç”¨ï¼‰
3. ã‚µãƒãƒ¼ãƒˆå¤–å…ƒç´ ã®BDEäºˆæ¸¬ãŒä¸æ­£ç¢ºï¼ˆãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹æ¨å®šã«ä¾å­˜ï¼‰
4. èª¤ã£ãŸç‰¹å¾´é‡ã«ã‚ˆã‚‹å­¦ç¿’ã‚’å›é¿

**NIST 17ã§ã®ã‚µãƒãƒ¼ãƒˆå¤–å…ƒç´ ã®ä¾‹**:
- Siï¼ˆã‚·ãƒªã‚³ãƒ³åŒ–åˆç‰©ã€ã‚·ãƒ­ã‚­ã‚µãƒ³ï¼‰
- Bï¼ˆãƒ›ã‚¦ç´ åŒ–åˆç‰©ï¼‰
- Seï¼ˆã‚»ãƒ¬ãƒ³åŒ–åˆç‰©ï¼‰
- Asï¼ˆãƒ’ç´ åŒ–åˆç‰©ï¼‰
- Ge, Al, Ti, Zr, etc.

**é™¤å¤–ã•ã‚Œã‚‹åŒ–åˆç‰©**: ç´„15,000ã‚¹ãƒšã‚¯ãƒˆãƒ«ï¼ˆ5%ï¼‰

#### BDE-db2ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè©³ç´°

**Paton Group BDE-db2**:
- ç·ãƒ‡ãƒ¼ã‚¿æ•°: **531,244 BDEå€¤**
- å…ƒç´ ç¨®: C, H, O, N, F, S, P, Cl, Br, Iï¼ˆ10å…ƒç´ ï¼‰
- ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: B3LYP/6-31G(d) DFTè¨ˆç®—
- è«–æ–‡: "A comprehensive database of bond dissociation enthalpies" (Paton et al.)

**BDNCMï¼ˆBonDNetå…¬å¼ï¼‰ã¨ã®æ¯”è¼ƒ**:
| é …ç›® | BDNCM (å…¬å¼) | BDE-db2 (æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ) |
|------|-------------|------------------------|
| ãƒ‡ãƒ¼ã‚¿æ•° | 64,312 | 531,244 |
| å…ƒç´ æ•° | 5 (C,H,O,F,Li) | 10 (C,H,O,N,F,S,P,Cl,Br,I) |
| ç”¨é€” | æœ‰æ©Ÿãƒªãƒã‚¦ãƒ é›»æ±  | æ±ç”¨æœ‰æ©ŸåŒ–åˆç‰© âœ… |
| ãƒãƒ­ã‚²ãƒ³å¯¾å¿œ | Fã®ã¿ | Cl, Br, Iå¯¾å¿œ âœ… |

**ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®NIST 17ã¨ã®é©åˆæ€§**:
- ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®NIST 17ã®**100%**ãŒ10å…ƒç´ å†…ã«åã¾ã‚‹ï¼ˆè¨­è¨ˆä¸Šä¿è¨¼ï¼‰
- ç’°çŠ¶åŒ–åˆç‰©ã€ãƒ˜ãƒ†ãƒ­ç’°åŒ–åˆç‰©ã®å¤šæ§˜æ€§ã«å¯¾å¿œ
- ãƒãƒ­ã‚²ãƒ³åŒ–åˆç‰©ï¼ˆè¾²è–¬ã€åŒ»è–¬å“ï¼‰ã®ã‚«ãƒãƒ¬ãƒƒã‚¸å‘ä¸Š

---

### GNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: 10-layer GATv2Conv

#### ãƒ¢ãƒ‡ãƒ«æ§‹æˆ

```python
import torch
import torch.nn as nn
from torch_geometric.nn import GATv2Conv, global_mean_pool

class QCGN2oEI(nn.Module):
    """
    QC-GN2oMS2 Architecture for EI-MS Prediction

    Key changes from original:
    - MS/MS â†’ EI-MS (fragmentation energy: variable â†’ 70eV fixed)
    - Edge features: BDE from BonDNet (BDE-db2 retrained)
    - Output: 1000-bin intensity distribution (m/z 50-1000)
    - Input: Filtered dataset (10 elements, MW <= 1000)
    """

    def __init__(
        self,
        node_dim: int = 128,       # Atom feature dimension
        edge_dim: int = 64,        # Edge feature dimension (includes BDE)
        hidden_dim: int = 256,     # Hidden layer dimension
        num_layers: int = 10,      # GATv2Conv layers
        num_heads: int = 8,        # Attention heads
        output_dim: int = 1000,    # Output spectrum bins (m/z 50-1000, 950 bins + 50 padding)
        dropout: float = 0.1
    ):
        super().__init__()

        # Node embedding
        self.node_encoder = nn.Sequential(
            nn.Linear(node_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout)
        )

        # Edge embedding (BDE + bond features)
        self.edge_encoder = nn.Sequential(
            nn.Linear(edge_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout)
        )

        # 10-layer GATv2Conv with residual connections
        self.gat_layers = nn.ModuleList()
        self.residual_layers = nn.ModuleList()

        for i in range(num_layers):
            # GATv2Conv layer
            self.gat_layers.append(
                GATv2Conv(
                    in_channels=hidden_dim,
                    out_channels=hidden_dim // num_heads,
                    heads=num_heads,
                    edge_dim=hidden_dim,  # Edge features
                    dropout=dropout,
                    concat=True,          # Concatenate heads
                    residual=True         # PyG 2.6.1+ feature
                )
            )

            # Residual connection projection
            self.residual_layers.append(
                nn.Linear(hidden_dim, hidden_dim)
            )

        # Global pooling + prediction head
        self.prediction_head = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim * 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, output_dim),
            nn.Softmax(dim=-1)  # Normalize to intensity distribution
        )

    def forward(self, data):
        """
        Args:
            data: PyG Data object
                - x: Node features [num_nodes, node_dim]
                - edge_index: Graph connectivity [2, num_edges]
                - edge_attr: Edge features (includes BDE) [num_edges, edge_dim]
                - batch: Batch assignment [num_nodes]

        Returns:
            spectrum: Predicted intensity [batch_size, 1000]
        """
        # Encode nodes and edges
        x = self.node_encoder(data.x)
        edge_attr = self.edge_encoder(data.edge_attr)

        # 10-layer GATv2Conv with residual connections
        for gat, residual in zip(self.gat_layers, self.residual_layers):
            x_res = residual(x)  # Residual projection
            x = gat(x, data.edge_index, edge_attr)
            x = x + x_res  # Residual addition
            x = torch.relu(x)

        # Global mean pooling
        x = global_mean_pool(x, data.batch)

        # Predict spectrum
        spectrum = self.prediction_head(x)

        return spectrum
```

#### ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ï¼ˆ128æ¬¡å…ƒï¼‰

**å®Ÿä½¿ç”¨**: 41æ¬¡å…ƒ
**äºˆå‚™**: 87æ¬¡å…ƒï¼ˆå°†æ¥ã®æ‹¡å¼µç”¨ã€ç¾åœ¨ã¯ã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼‰

| ã‚«ãƒ†ã‚´ãƒª | æ¬¡å…ƒ | å†…å®¹ |
|---------|------|------|
| **åŸå­ç¨®** | 10 | C, H, O, N, F, S, P, Cl, Br, I (one-hot) |
| **ãƒã‚¤ãƒ–ãƒªãƒ€ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³** | 5 | SP, SP2, SP3, SP3D, SP3D2 (one-hot) |
| **å½¢å¼é›»è·** | 3 | -1, 0, +1 (one-hot) |
| **èŠ³é¦™æ—æ€§** | 1 | Binary (aromatic/aliphatic) |
| **ç’°æ§‹é€ ** | 1 | Binary (in ring/not in ring) |
| **æ°´ç´ çµåˆæ•°** | 5 | 0, 1, 2, 3, 4+ (one-hot) |
| **æ¬¡æ•°ï¼ˆdegreeï¼‰** | 6 | 0, 1, 2, 3, 4, 5+ (one-hot) |
| **ãƒ©ã‚¸ã‚«ãƒ«é›»å­** | 3 | 0, 1, 2 (one-hot) |
| **ã‚­ãƒ©ãƒªãƒ†ã‚£** | 3 | None, R, S (one-hot) |
| **éƒ¨åˆ†é›»è·** | 1 | Gasteiger charge (continuous) |
| **åŸå­é‡** | 1 | Normalized atomic mass (continuous) |
| **ãƒ•ã‚¡ãƒ³ der WaalsåŠå¾„** | 1 | Normalized vdW radius (continuous) |
| **é›»æ°—é™°æ€§åº¦** | 1 | Pauling electronegativity (continuous) |
| **äºˆå‚™** | 87 | å°†æ¥ã®æ‹¡å¼µç”¨ï¼ˆMorgan fingerprintã€QMè¨˜è¿°å­ã€ã‚°ãƒ©ãƒ•åŸ‹ã‚è¾¼ã¿ãªã©ï¼‰ |

**äºˆå‚™æ¬¡å…ƒã®è¨­è¨ˆæ„å›³**:
- å°†æ¥ã®ãƒ¢ãƒ‡ãƒ«æ”¹å–„æ™‚ã«ç‰¹å¾´é‡ã‚’è¿½åŠ å¯èƒ½ï¼ˆå¾Œæ–¹äº’æ›æ€§ç¶­æŒï¼‰
- ãƒ¡ãƒ¢ãƒªã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆæœ€é©åŒ–ï¼ˆ2ã®ç´¯ä¹—æ¬¡å…ƒ: 128 = 2^7ï¼‰
- RTX 5070 Tiï¼ˆ16GBï¼‰ã§ã¯280,000ã‚°ãƒ©ãƒ•ã§ã‚‚ç´„1.3GBã¨è¨±å®¹ç¯„å›²å†…
- Encoderå±¤ã¯1å±¤ã®ã¿ãªã®ã§è¨ˆç®—ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰æœ€å°

**æ³¨æ„**: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚Šã€ã‚µãƒãƒ¼ãƒˆå¤–å…ƒç´ ã¯å…¥åŠ›ã•ã‚Œãªã„ï¼ˆåŸå­ç¨®10æ¬¡å…ƒã§å®Œå…¨ã‚«ãƒãƒ¼ï¼‰

**å®Ÿè£…ä¾‹**:
```python
from rdkit import Chem
from rdkit.Chem import Descriptors, rdMolDescriptors
import numpy as np

# ã‚µãƒãƒ¼ãƒˆå…ƒç´ ï¼ˆå³å¯†ã«10å…ƒç´ ã®ã¿ï¼‰
SUPPORTED_ELEMENTS = ['C', 'H', 'O', 'N', 'F', 'S', 'P', 'Cl', 'Br', 'I']

def get_atom_features(atom: Chem.Atom) -> np.ndarray:
    """Extract 128-dimensional atom features"""

    # Atom type (10-dim one-hot) - ã‚µãƒãƒ¼ãƒˆå…ƒç´ ã®ã¿
    atom_symbol = atom.GetSymbol()
    if atom_symbol not in SUPPORTED_ELEMENTS:
        raise ValueError(f"Unsupported element: {atom_symbol}. "
                         "This should have been filtered in Phase 1.2")
    atom_type = one_hot(atom_symbol, SUPPORTED_ELEMENTS)

    # Hybridization (5-dim one-hot)
    hybridizations = [
        Chem.HybridizationType.SP,
        Chem.HybridizationType.SP2,
        Chem.HybridizationType.SP3,
        Chem.HybridizationType.SP3D,
        Chem.HybridizationType.SP3D2
    ]
    hybrid = one_hot(atom.GetHybridization(), hybridizations)

    # Formal charge (3-dim one-hot)
    charge = one_hot(atom.GetFormalCharge(), [-1, 0, 1])

    # Binary features
    aromatic = [int(atom.GetIsAromatic())]
    in_ring = [int(atom.IsInRing())]

    # Hydrogen count (5-dim one-hot)
    num_h = one_hot(atom.GetTotalNumHs(), [0, 1, 2, 3, 4])

    # Degree (6-dim one-hot)
    degree = one_hot(atom.GetDegree(), [0, 1, 2, 3, 4, 5])

    # Radical electrons (3-dim one-hot)
    radical = one_hot(atom.GetNumRadicalElectrons(), [0, 1, 2])

    # Chirality (3-dim one-hot)
    chiralities = [
        Chem.ChiralType.CHI_UNSPECIFIED,
        Chem.ChiralType.CHI_TETRAHEDRAL_CW,
        Chem.ChiralType.CHI_TETRAHEDRAL_CCW
    ]
    chirality = one_hot(atom.GetChiralTag(), chiralities)

    # Continuous features
    partial_charge = [atom.GetDoubleProp('_GasteigerCharge') if atom.HasProp('_GasteigerCharge') else 0.0]
    atomic_mass = [atom.GetMass() / 100.0]  # Normalize
    vdw_radius = [Chem.GetPeriodicTable().GetRvdw(atom.GetSymbol()) / 2.0]  # Normalize
    electronegativity = [Chem.GetPeriodicTable().GetElectronegativity(atom.GetSymbol()) / 4.0]  # Normalize

    # Concatenate (total: 10+5+3+1+1+5+6+3+3+1+1+1+1 = 41 dims)
    # Pad to 128 with zeros (87 reserved dimensions)
    features = np.concatenate([
        atom_type, hybrid, charge, aromatic, in_ring,
        num_h, degree, radical, chirality,
        partial_charge, atomic_mass, vdw_radius, electronegativity
    ])

    padded = np.zeros(128)
    padded[:len(features)] = features

    return padded

def one_hot(value, choices):
    """One-hot encoding with out-of-vocabulary handling"""
    encoding = [0] * len(choices)
    if value in choices:
        encoding[choices.index(value)] = 1
    return encoding
```

#### ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼ˆ64æ¬¡å…ƒï¼‰

**å®Ÿä½¿ç”¨**: 12æ¬¡å…ƒ
**äºˆå‚™**: 52æ¬¡å…ƒï¼ˆå°†æ¥ã®æ‹¡å¼µç”¨ã€ç¾åœ¨ã¯ã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼‰

| ã‚«ãƒ†ã‚´ãƒª | æ¬¡å…ƒ | å†…å®¹ |
|---------|------|------|
| **BDEï¼ˆé‡è¦ï¼‰** | 1 | Bond Dissociation Energy from BonDNet (kcal/mol, normalized) |
| **çµåˆæ¬¡æ•°** | 4 | Single, Double, Triple, Aromatic (one-hot) |
| **ç’°å†…çµåˆ** | 1 | Binary (in ring/not in ring) |
| **å…±å½¹** | 1 | Binary (conjugated/not conjugated) |
| **ç«‹ä½“åŒ–å­¦** | 3 | None, E, Z (one-hot) |
| **å›è»¢å¯èƒ½æ€§** | 1 | Binary (rotatable/rigid) |
| **çµåˆè·é›¢** | 1 | Normalized bond length (Ã…) |
| **äºˆå‚™** | 52 | å°†æ¥ã®æ‹¡å¼µç”¨ï¼ˆWiberg bond orderã€Mayer bond orderã€é›»å­å¯†åº¦ãªã©ï¼‰ |

**äºˆå‚™æ¬¡å…ƒã®è¨­è¨ˆæ„å›³**ï¼ˆãƒãƒ¼ãƒ‰ç‰¹å¾´ã¨åŒæ§˜ï¼‰:
- å°†æ¥ã®æ‹¡å¼µæ€§ï¼ˆQMè¨ˆç®—ç”±æ¥ã®çµåˆæ¬¡æ•°ãªã©ï¼‰
- ãƒ¡ãƒ¢ãƒªã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆæœ€é©åŒ–ï¼ˆ2ã®ç´¯ä¹—æ¬¡å…ƒ: 64 = 2^6ï¼‰

**BDEæ­£è¦åŒ–**:
```python
def normalize_bde(bde_kcal_mol: float) -> float:
    """
    Normalize BDE to [0, 1] range

    Typical BDE ranges:
    - C-C single: 85 kcal/mol
    - C=C double: 146 kcal/mol
    - C-H: 105 kcal/mol
    - O-H: 110 kcal/mol
    - Aromatic C-C: 120 kcal/mol

    Range: 50-200 kcal/mol
    """
    return (bde_kcal_mol - 50.0) / 150.0
```

---

## Phase 0: BDE-db2ç’°å¢ƒæ§‹ç¯‰

ï¼ˆv4.0ã¨åŒã˜å†…å®¹ã®ãŸã‚çœç•¥ - å¤‰æ›´ãªã—ï¼‰

---

## Phase 1: ãƒ‡ãƒ¼ã‚¿æº–å‚™

### 1.1 NIST 17ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿

```python
# src/data/nist_loader.py
"""
NIST 17 EI-MS Data Loader
"""

import pandas as pd
import numpy as np
from rdkit import Chem
from pathlib import Path
from typing import List, Dict, Tuple

class NIST17Loader:
    """
    NIST 17 EI-MS Database Loader

    Expected format: MSP file with NIST spectra
    """

    def __init__(self, nist_path: str = "data/external/nist17/mainlib"):
        self.nist_path = Path(nist_path)

    def parse_msp(self, msp_file: str) -> List[Dict]:
        """
        Parse NIST MSP file

        Returns:
            List of dicts with keys: name, smiles, spectrum
        """
        spectra = []
        current_spectrum = {}
        current_peaks = []

        with open(msp_file, 'r', encoding='utf-8', errors='ignore') as f:
            for line in f:
                line = line.strip()

                if line.startswith("Name:"):
                    if current_spectrum:
                        current_spectrum['spectrum'] = current_peaks
                        spectra.append(current_spectrum)
                    current_spectrum = {'name': line.split(":", 1)[1].strip()}
                    current_peaks = []

                elif line.startswith("SMILES:"):
                    current_spectrum['smiles'] = line.split(":", 1)[1].strip()

                elif line.startswith("Num Peaks:"):
                    num_peaks = int(line.split(":")[1].strip())

                elif line and line[0].isdigit():
                    # Peak data: "m/z intensity; m/z intensity; ..."
                    for peak in line.split(";"):
                        peak = peak.strip()
                        if peak:
                            mz, intensity = peak.split()
                            current_peaks.append((int(mz), int(intensity)))

        # Add last spectrum
        if current_spectrum:
            current_spectrum['spectrum'] = current_peaks
            spectra.append(current_spectrum)

        return spectra

    def load_all_spectra(self) -> pd.DataFrame:
        """Load all NIST 17 spectra into DataFrame"""

        all_spectra = []

        # NIST 17 has multiple MSP files
        msp_files = list(self.nist_path.glob("*.msp"))

        for msp_file in msp_files:
            print(f"Loading {msp_file.name}...")
            spectra = self.parse_msp(msp_file)
            all_spectra.extend(spectra)

        df = pd.DataFrame(all_spectra)

        print(f"Total spectra loaded: {len(df)}")

        return df

    def spectrum_to_array(self, peaks: List[Tuple[int, int]],
                          mz_range: Tuple[int, int] = (50, 1000)) -> np.ndarray:
        """
        Convert peak list to fixed-size array

        Args:
            peaks: List of (m/z, intensity) tuples
            mz_range: (min_mz, max_mz)

        Returns:
            spectrum_array: [950] array for m/z 50-1000
        """
        min_mz, max_mz = mz_range
        spectrum = np.zeros(max_mz - min_mz)

        for mz, intensity in peaks:
            if min_mz <= mz < max_mz:
                spectrum[mz - min_mz] = intensity

        # Normalize to [0, 1]
        if spectrum.max() > 0:
            spectrum = spectrum / spectrum.max()

        return spectrum
```

---

### 1.2 ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆNEW!ï¼‰

**ç›®çš„**: BonDNetå¯¾å¿œå…ƒç´ ãƒ»åˆ†å­é‡ç¯„å›²ã«é™å®šã—ãŸé«˜å“è³ªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ§‹ç¯‰

```python
# src/data/filters.py
"""
Data filtering for NIST 17 dataset
"""

from rdkit import Chem
from rdkit.Chem import Descriptors
import pandas as pd
from typing import Set
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Supported elements (BonDNet BDE-db2 coverage)
SUPPORTED_ELEMENTS: Set[str] = {'C', 'H', 'O', 'N', 'F', 'S', 'P', 'Cl', 'Br', 'I'}

def filter_supported_elements(df: pd.DataFrame) -> pd.DataFrame:
    """
    Filter molecules containing only supported elements

    Args:
        df: DataFrame with 'smiles' column

    Returns:
        Filtered DataFrame
    """

    def contains_only_supported(smiles: str) -> bool:
        """Check if molecule contains only supported elements"""
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            return False

        for atom in mol.GetAtoms():
            if atom.GetSymbol() not in SUPPORTED_ELEMENTS:
                logger.debug(f"Unsupported element {atom.GetSymbol()} in {smiles}")
                return False
        return True

    initial_count = len(df)
    logger.info(f"Starting element filtering: {initial_count} spectra")

    mask = df['smiles'].apply(contains_only_supported)
    filtered_df = df[mask].copy()

    removed = initial_count - len(filtered_df)
    logger.info(f"âœ… Element filter complete:")
    logger.info(f"   Retained: {len(filtered_df)} / {initial_count} spectra")
    logger.info(f"   Removed:  {removed} spectra ({removed/initial_count*100:.2f}%)")
    logger.info(f"   Supported elements: {', '.join(sorted(SUPPORTED_ELEMENTS))}")

    return filtered_df


def filter_by_molecular_weight(
    df: pd.DataFrame,
    min_mw: float = 50.0,
    max_mw: float = 1000.0
) -> pd.DataFrame:
    """
    Filter molecules by molecular weight

    Args:
        df: DataFrame with 'smiles' column
        min_mw: Minimum molecular weight (default: 50.0)
        max_mw: Maximum molecular weight (default: 1000.0)

    Returns:
        Filtered DataFrame
    """

    def get_mw(smiles: str) -> float:
        """Calculate molecular weight"""
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            return 0.0
        return Descriptors.MolWt(mol)

    initial_count = len(df)
    logger.info(f"Starting MW filtering: {initial_count} spectra")

    # Calculate molecular weights
    df['mw'] = df['smiles'].apply(get_mw)

    # Filter by MW range
    filtered_df = df[(df['mw'] >= min_mw) & (df['mw'] <= max_mw)].copy()

    removed = initial_count - len(filtered_df)
    logger.info(f"âœ… MW filter complete:")
    logger.info(f"   Retained: {len(filtered_df)} / {initial_count} spectra")
    logger.info(f"   Removed:  {removed} spectra ({removed/initial_count*100:.2f}%)")
    logger.info(f"   MW range: {min_mw} - {max_mw} Da")
    logger.info(f"   Actual MW range: {filtered_df['mw'].min():.1f} - {filtered_df['mw'].max():.1f} Da")
    logger.info(f"   Mean MW: {filtered_df['mw'].mean():.1f} Â± {filtered_df['mw'].std():.1f} Da")

    return filtered_df


def filter_valid_smiles(df: pd.DataFrame) -> pd.DataFrame:
    """
    Filter valid SMILES strings

    Args:
        df: DataFrame with 'smiles' column

    Returns:
        Filtered DataFrame
    """

    def is_valid_smiles(smiles: str) -> bool:
        """Check if SMILES is valid"""
        if pd.isna(smiles) or smiles == '':
            return False
        mol = Chem.MolFromSmiles(smiles)
        return mol is not None

    initial_count = len(df)
    logger.info(f"Starting SMILES validation: {initial_count} spectra")

    mask = df['smiles'].apply(is_valid_smiles)
    filtered_df = df[mask].copy()

    removed = initial_count - len(filtered_df)
    logger.info(f"âœ… SMILES validation complete:")
    logger.info(f"   Retained: {len(filtered_df)} / {initial_count} spectra")
    logger.info(f"   Removed:  {removed} spectra ({removed/initial_count*100:.2f}%)")

    return filtered_df


def apply_all_filters(
    df: pd.DataFrame,
    min_mw: float = 50.0,
    max_mw: float = 1000.0
) -> pd.DataFrame:
    """
    Apply all data filters sequentially

    Args:
        df: DataFrame with 'smiles' column
        min_mw: Minimum molecular weight
        max_mw: Maximum molecular weight

    Returns:
        Fully filtered DataFrame
    """

    initial_count = len(df)
    logger.info("=" * 60)
    logger.info("Starting comprehensive data filtering")
    logger.info("=" * 60)

    # Filter 1: Valid SMILES
    df = filter_valid_smiles(df)

    # Filter 2: Supported elements only
    df = filter_supported_elements(df)

    # Filter 3: Molecular weight range
    df = filter_by_molecular_weight(df, min_mw, max_mw)

    final_count = len(df)
    retention_rate = final_count / initial_count * 100

    logger.info("=" * 60)
    logger.info("Filtering complete")
    logger.info("=" * 60)
    logger.info(f"Initial dataset:  {initial_count} spectra")
    logger.info(f"Final dataset:    {final_count} spectra")
    logger.info(f"Retention rate:   {retention_rate:.2f}%")
    logger.info(f"Total removed:    {initial_count - final_count} spectra")
    logger.info("=" * 60)

    return df
```

**å®Ÿè¡Œä¾‹**:
```python
from src.data.nist_loader import NIST17Loader
from src.data.filters import apply_all_filters

# Load NIST 17
loader = NIST17Loader("data/external/nist17/mainlib")
df = loader.load_all_spectra()
print(f"Loaded: {len(df)} spectra")

# Apply all filters
df_filtered = apply_all_filters(df, min_mw=50.0, max_mw=1000.0)
print(f"After filtering: {len(df_filtered)} spectra")
```

**äºˆæƒ³å‡ºåŠ›**:
```
Loaded: 300,000 spectra
============================================================
Starting comprehensive data filtering
============================================================
Starting SMILES validation: 300,000 spectra
âœ… SMILES validation complete:
   Retained: 298,000 / 300,000 spectra
   Removed:  2,000 spectra (0.67%)
Starting element filtering: 298,000 spectra
âœ… Element filter complete:
   Retained: 283,000 / 298,000 spectra
   Removed:  15,000 spectra (5.03%)
   Supported elements: Br, C, Cl, F, H, I, N, O, P, S
Starting MW filtering: 283,000 spectra
âœ… MW filter complete:
   Retained: 280,000 / 283,000 spectra
   Removed:  3,000 spectra (1.06%)
   MW range: 50.0 - 1000.0 Da
   Actual MW range: 52.1 - 999.8 Da
   Mean MW: 247.3 Â± 152.8 Da
============================================================
Filtering complete
============================================================
Initial dataset:  300,000 spectra
Final dataset:    280,000 spectra
Retention rate:   93.33%
Total removed:    20,000 spectra
============================================================
After filtering: 280,000 spectra
```

---

### 1.3 BDEå‰è¨ˆç®—ï¼ˆBonDNet BDE-db2ï¼‰

ï¼ˆv4.0ã¨åŒã˜å†…å®¹ - å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãŒ280,000ã«å¤‰æ›´ã•ã‚ŒãŸã®ã¿ï¼‰

**å®Ÿè¡Œæ™‚é–“è¦‹ç©ã‚‚ã‚Š**:
```
280,000 molecules Ã— 15ms/molecule = 4,200 seconds = 70 minutes
```

---

### 1.4 PyG Graphç”Ÿæˆ

ï¼ˆv4.0ã¨åŒã˜å†…å®¹ - å¤‰æ›´ãªã—ï¼‰

---

### 1.5 çµ±åˆãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```python
# scripts/prepare_dataset.py
"""
Prepare complete dataset with filtering, BDE calculation, and PyG graphs
"""

from src.data.nist_loader import NIST17Loader
from src.data.filters import apply_all_filters
from src.data.bde_calculator import BDECalculator
from src.data.graph_generator import GraphGenerator
import torch
from pathlib import Path
from tqdm import tqdm
from sklearn.model_selection import train_test_split
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def prepare_full_dataset():
    """
    Full pipeline: NIST â†’ Filter â†’ BDE â†’ PyG Graph â†’ HDF5
    """

    # Step 1: Load NIST 17
    logger.info("=" * 60)
    logger.info("Step 1: Loading NIST 17 data")
    logger.info("=" * 60)
    nist_loader = NIST17Loader("data/external/nist17/mainlib")
    df = nist_loader.load_all_spectra()
    logger.info(f"Loaded {len(df)} spectra from NIST 17")

    # Step 2: Apply data filters
    logger.info("\n" + "=" * 60)
    logger.info("Step 2: Data Filtering")
    logger.info("=" * 60)
    df = apply_all_filters(df, min_mw=50.0, max_mw=1000.0)
    logger.info(f"After filtering: {len(df)} spectra")

    # Step 3: Calculate BDE for all molecules
    logger.info("\n" + "=" * 60)
    logger.info("Step 3: Calculating BDE (BonDNet BDE-db2)")
    logger.info("=" * 60)
    bde_calc = BDECalculator(
        model_path="models/bondnet_bde_db2_best.pth",
        device="cuda"
    )
    bde_calc.batch_calculate(
        smiles_list=df['smiles'].tolist(),
        output_hdf5="data/processed/bde_cache.h5"
    )

    # Step 4: Generate PyG graphs
    logger.info("\n" + "=" * 60)
    logger.info("Step 4: Generating PyG graphs")
    logger.info("=" * 60)
    graph_gen = GraphGenerator("data/processed/bde_cache.h5")

    graphs = []
    for idx, row in tqdm(df.iterrows(), total=len(df), desc="Generating graphs"):
        spectrum_array = nist_loader.spectrum_to_array(row['spectrum'])
        graph = graph_gen.smiles_to_graph(
            smiles=row['smiles'],
            spectrum=spectrum_array,
            molecule_idx=idx
        )
        if graph is not None:
            graphs.append(graph)

    logger.info(f"Generated {len(graphs)} valid graphs")

    # Step 5: Train/Val/Test split
    logger.info("\n" + "=" * 60)
    logger.info("Step 5: Splitting dataset")
    logger.info("=" * 60)

    train_graphs, temp_graphs = train_test_split(graphs, test_size=0.2, random_state=42)
    val_graphs, test_graphs = train_test_split(temp_graphs, test_size=0.5, random_state=42)

    logger.info(f"Train: {len(train_graphs)} ({len(train_graphs)/len(graphs)*100:.1f}%)")
    logger.info(f"Val:   {len(val_graphs)} ({len(val_graphs)/len(graphs)*100:.1f}%)")
    logger.info(f"Test:  {len(test_graphs)} ({len(test_graphs)/len(graphs)*100:.1f}%)")

    # Step 6: Save to disk
    logger.info("\n" + "=" * 60)
    logger.info("Step 6: Saving datasets")
    logger.info("=" * 60)

    output_dir = Path("data/processed")
    output_dir.mkdir(parents=True, exist_ok=True)

    for split, split_graphs in [('train', train_graphs), ('val', val_graphs), ('test', test_graphs)]:
        output_path = output_dir / f"nist17_{split}.pt"
        torch.save(split_graphs, output_path)
        logger.info(f"âœ… Saved {split}: {output_path} ({len(split_graphs)} graphs)")

    logger.info("\n" + "=" * 60)
    logger.info("âœ… Dataset preparation complete!")
    logger.info("=" * 60)

if __name__ == "__main__":
    prepare_full_dataset()
```

**å®Ÿè¡Œ**:
```bash
python scripts/prepare_dataset.py
```

**æ¨å®šæ™‚é–“**:
- NISTèª­ã¿è¾¼ã¿: 30åˆ†
- ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: 10åˆ†ï¼ˆNEW!ï¼‰
- BDEè¨ˆç®—: 70åˆ†
- PyG Graphç”Ÿæˆ: 60åˆ†
- **åˆè¨ˆ: ç´„2æ™‚é–“50åˆ†**

---

## Phase 2: GNNå­¦ç¿’

ï¼ˆv4.0ã¨åŒã˜å†…å®¹ - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚ºãŒ280,000ã«å¤‰æ›´ã•ã‚ŒãŸã®ã¿ï¼‰

### 2.3 å­¦ç¿’æ™‚é–“è¦‹ç©ã‚‚ã‚Šï¼ˆæ›´æ–°ï¼‰

**1ã‚¨ãƒãƒƒã‚¯ã®æ™‚é–“**:
```
224,000 samples (train) Ã· 32 batch_size = 7,000 iterations
7,000 iterations Ã— 0.8 sec/iter = 5,600 sec = 1.56 hours
```

**åˆè¨ˆå­¦ç¿’æ™‚é–“**:
```
300 epochs Ã— 1.56 hours = 468 hours â†’ early stoppingã§ç´„48æ™‚é–“ï¼ˆ30ã‚¨ãƒãƒƒã‚¯ç¨‹åº¦ã§åæŸæƒ³å®šï¼‰
```

---

## Phase 3: è©•ä¾¡

ï¼ˆv4.0ã¨åŒã˜å†…å®¹ - å¤‰æ›´ãªã—ï¼‰

---

## è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°

### config.ymlï¼ˆãƒ¡ã‚¤ãƒ³è¨­å®šã€æ›´æ–°ç‰ˆï¼‰

```yaml
# config.yml - Main Configuration (v4.1)

project:
  name: "QC-GN2oEI"
  version: "2.1"
  description: "Physics-informed GNN for EI-MS prediction with BonDNet BDE-db2 and data filtering"

# BDE Configuration
bde:
  backend: "bondnet"  # Fixed (only option)

  bondnet:
    model_type: "bde-db2"  # Default model (retrained on BDE-db2)
    model_path: "models/bondnet_bde_db2_best.pth"
    dataset_path: "data/external/bde-db2"
    device: "cuda"
    batch_size: 256

    # Fallback for unsupported elements/structures
    fallback:
      aromatic_ring_bond: 120.0  # kcal/mol
      aliphatic_ring_bond: 85.0  # kcal/mol
      default_single_bond: 85.0
      default_double_bond: 146.0
      default_triple_bond: 200.0

# Data paths
data:
  nist17_path: "data/external/nist17/mainlib"
  bde_cache: "data/processed/bde_cache.h5"
  train_data: "data/processed/nist17_train.pt"
  val_data: "data/processed/nist17_val.pt"
  test_data: "data/processed/nist17_test.pt"

  # Data filtering (NEW in v4.1)
  filtering:
    # Supported elements (BonDNet BDE-db2 coverage)
    supported_elements: ['C', 'H', 'O', 'N', 'F', 'S', 'P', 'Cl', 'Br', 'I']

    # Molecular weight range (aligned with output m/z range)
    min_molecular_weight: 50.0   # Da
    max_molecular_weight: 1000.0  # Da

    # SMILES validation
    validate_smiles: true

# Model architecture
model:
  type: "QCGN2oEI"

  # Node/Edge dimensions
  node_dim: 128  # 41 used + 87 reserved for future extensions
  edge_dim: 64   # 12 used + 52 reserved for future extensions

  # GNN layers
  hidden_dim: 256
  num_layers: 10
  num_heads: 8

  # Output
  output_dim: 1000  # m/z 50-1000 (950 bins + 50 padding)

  # Regularization
  dropout: 0.1

  # Advanced features
  use_residual: true
  use_edge_features: true
  global_pooling: "mean"

# Training
training:
  num_epochs: 300
  batch_size: 32
  learning_rate: 0.001
  weight_decay: 1e-5

  # Optimizer
  optimizer: "RAdam"  # Same as QC-GN2oMS2

  # Scheduler
  scheduler: "CosineAnnealingLR"
  scheduler_params:
    T_max: 300
    eta_min: 1e-6

  # Loss function
  loss: "cosine_similarity"

  # Early stopping
  early_stopping_patience: 50

  # Checkpointing
  save_every: 10  # Save checkpoint every 10 epochs
  checkpoint_dir: "checkpoints"

# Evaluation
evaluation:
  metrics:
    - "cosine_similarity"
    - "top_k_recall"
    - "mse"
    - "rmse"

  top_k_values: [5, 10, 20, 50]

  # Visualization
  plot_examples: 10
  plot_dir: "results/plots"

# Hardware
hardware:
  device: "cuda"
  gpu_id: 0
  num_workers: 4
  pin_memory: true

  # Mixed precision training
  use_amp: true
  amp_dtype: "float16"

  # Memory optimization
  gradient_accumulation_steps: 1
  empty_cache_every: 100  # Empty CUDA cache every 100 batches

# Logging
logging:
  use_wandb: true
  wandb_project: "qcgn2oei"
  wandb_entity: null  # Set your wandb username

  log_every: 10  # Log every 10 batches
  save_predictions: true

# Reproducibility
seed: 42
deterministic: true
```

---

## é–‹ç™ºç’°å¢ƒæ§‹ç¯‰

ï¼ˆv4.0ã¨åŒã˜å†…å®¹ - å¤‰æ›´ãªã—ï¼‰

---

## ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³

### å…¨ä½“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆv4.1æ›´æ–°ç‰ˆï¼‰

| ãƒ•ã‚§ãƒ¼ã‚º | ã‚¿ã‚¹ã‚¯ | æ¨å®šæ™‚é–“ | ç´¯ç©æ™‚é–“ |
|---------|--------|---------|---------|
| **Phase 0** | BDE-db2ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ | 30åˆ† | 30åˆ† |
| **Phase 0** | ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç† | 3æ™‚é–“ | 3.5æ™‚é–“ |
| **Phase 0** | BonDNetå†å­¦ç¿’ | 48-72æ™‚é–“ | 51.5-75.5æ™‚é–“ |
| **Phase 0** | ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ | 1æ™‚é–“ | 52.5-76.5æ™‚é–“ |
| **Phase 1** | NISTèª­ã¿è¾¼ã¿ | 30åˆ† | 53-77æ™‚é–“ |
| **Phase 1** | ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆNEW!ï¼‰ | 10åˆ† | 53.17-77.17æ™‚é–“ |
| **Phase 1** | BDEè¨ˆç®—ï¼ˆBonDNetã€280Kï¼‰ | 70åˆ† | 54.33-78.33æ™‚é–“ |
| **Phase 1** | PyG Graphç”Ÿæˆ | 60åˆ† | 55.33-79.33æ™‚é–“ |
| **Phase 2** | GNNå­¦ç¿’ | 48æ™‚é–“ | 103.33-127.33æ™‚é–“ |
| **Phase 3** | è©•ä¾¡ | 2æ™‚é–“ | 105.33-129.33æ™‚é–“ |
| **åˆè¨ˆ** | - | **105-130æ™‚é–“** | **4.4-5.4æ—¥** |

### ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒ‘ã‚¹

```
Phase 0 (BonDNetå†å­¦ç¿’) â†’ Phase 1 (ãƒ•ã‚£ãƒ«ã‚¿+BDEè¨ˆç®—) â†’ Phase 2 (GNNå­¦ç¿’) â†’ Phase 3 (è©•ä¾¡)
```

**v4.1ã§ã®å¤‰æ›´**:
- ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°è¿½åŠ : +10åˆ†
- BDEè¨ˆç®—æ™‚é–“: 75åˆ† â†’ 70åˆ†ï¼ˆãƒ‡ãƒ¼ã‚¿æ¸›å°‘ã«ã‚ˆã‚Š-5åˆ†ï¼‰
- æ­£å‘³ã®æ™‚é–“å¢—åŠ : +5åˆ†ï¼ˆèª¤å·®ç¯„å›²å†…ï¼‰

---

## å‚è€ƒæ–‡çŒ®

ï¼ˆv4.0ã¨åŒã˜å†…å®¹ - å¤‰æ›´ãªã—ï¼‰

---

## ã¾ã¨ã‚

### v4.1ã®ä¸»è¦ãªæ”¹å–„ç‚¹

1. **ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã®æ˜ç¤ºåŒ–**: ã‚µãƒãƒ¼ãƒˆå…ƒç´ ãƒ»åˆ†å­é‡ã®å³å¯†ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
2. **é«˜å“è³ªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**: 280,000ã‚¹ãƒšã‚¯ãƒˆãƒ«ï¼ˆ93.3% retentionï¼‰ã€10å…ƒç´ ãƒ»MW<=1000ã«çµ±ä¸€
3. **äºˆå‚™æ¬¡å…ƒã®æ˜ç¢ºåŒ–**: å°†æ¥ã®æ‹¡å¼µæ€§ã®ãŸã‚ã®è¨­è¨ˆã§ã‚ã‚‹ã“ã¨ã‚’èª¬æ˜
4. **ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã®ä¿è¨¼**: BonDNetå¯¾å¿œå…ƒç´ ãƒ»å‡ºåŠ›ç¯„å›²ï¼ˆm/z 50-1000ï¼‰ã¨ã®å®Œå…¨æ•´åˆ

### æœŸå¾…ã•ã‚Œã‚‹æˆæœ

- **ç²¾åº¦**: Cosine Similarity > 0.85
- **é€Ÿåº¦**: æ¨è«–15ms/åˆ†å­ï¼ˆå®Ÿç”¨ãƒ¬ãƒ™ãƒ«ï¼‰
- **ã‚«ãƒãƒ¬ãƒƒã‚¸**: NIST 17ã®93.3%ï¼ˆé«˜å“è³ªåŒ–åˆç‰©ã®ã¿ï¼‰
- **è§£é‡ˆæ€§**: BDEã‚¨ãƒƒã‚¸ç‰¹å¾´ã«ã‚ˆã‚‹ç‰©ç†åŒ–å­¦çš„è§£é‡ˆå¯èƒ½æ€§
- **ãƒ­ãƒã‚¹ãƒˆæ€§**: ã‚µãƒãƒ¼ãƒˆå¤–å…ƒç´ ãƒ»é«˜MWåŒ–åˆç‰©ã‚’é™¤å¤–ã—ãŸå®‰å®šå­¦ç¿’

---

**Document Version**: 4.1
**Last Updated**: 2025-12-02
**Status**: Ready for Implementation (with comprehensive data filtering)
