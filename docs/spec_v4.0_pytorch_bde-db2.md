# QC-GN2oMS2-EI ã‚·ã‚¹ãƒ†ãƒ è©³ç´°æŠ€è¡“ä»•æ§˜æ›¸ v4.0
## PyTorchçµ±ä¸€ç’°å¢ƒãƒ»BonDNet BDE-db2ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç‰ˆ

**ä½œæˆæ—¥**: 2025-12-02
**å¯¾è±¡ã‚·ã‚¹ãƒ†ãƒ **: NExtIMS (NIST EI-MS Prediction System)
**åŸºç›¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: QC-GN2oMS2 (PNNL)
**ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢**: NVIDIA GeForce RTX 5070 Ti (Blackwell sm_120)

---

## ğŸ“‹ ç›®æ¬¡

1. [ä¸»è¦å¤‰æ›´ç‚¹ï¼ˆv3.0 â†’ v4.0ï¼‰](#ä¸»è¦å¤‰æ›´ç‚¹v30--v40)
2. [ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦](#ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦)
3. [ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ](#ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ)
4. [Phase 0: BDE-db2ç’°å¢ƒæ§‹ç¯‰](#phase-0-bde-db2ç’°å¢ƒæ§‹ç¯‰)
5. [Phase 1: ãƒ‡ãƒ¼ã‚¿æº–å‚™](#phase-1-ãƒ‡ãƒ¼ã‚¿æº–å‚™)
6. [Phase 2: GNNå­¦ç¿’](#phase-2-gnnå­¦ç¿’)
7. [Phase 3: è©•ä¾¡](#phase-3-è©•ä¾¡)
8. [è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°](#è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°)
9. [é–‹ç™ºç’°å¢ƒæ§‹ç¯‰](#é–‹ç™ºç’°å¢ƒæ§‹ç¯‰)
10. [ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³](#ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³)
11. [å‚è€ƒæ–‡çŒ®](#å‚è€ƒæ–‡çŒ®)

---

## ä¸»è¦å¤‰æ›´ç‚¹ï¼ˆv3.0 â†’ v4.0ï¼‰

### âŒ å‰Šé™¤ã•ã‚ŒãŸæ©Ÿèƒ½

| å‰Šé™¤é …ç›® | ç†ç”± |
|---------|------|
| **xTB GPUè¨ˆç®—** | BDEã‚’ç›´æ¥è¨ˆç®—ã§ããªã„ï¼ˆHessianè¡Œåˆ—ã®ã¿ï¼‰ã€‚é–“æ¥çš„ãªã‚¨ãƒãƒ«ã‚®ãƒ¼å·®åˆ†æ³•ã¯10ç§’/çµåˆã¨é…ãã€ãƒ©ã‚¸ã‚«ãƒ«è¨ˆç®—ã®æ•°å€¤ä¸å®‰å®šæ€§ã‚‚å•é¡Œ |
| **ALFABET** | TensorFlowä¾å­˜ã€‚PyTorchçµ±ä¸€ç’°å¢ƒã¨ç«¶åˆã™ã‚‹ãŸã‚ä¸é©åˆ |
| **ãƒ—ãƒ©ã‚¬ãƒ–ãƒ«BDEãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰** | xTB/ALFABETå‰Šé™¤ã«ã‚ˆã‚Šå˜ä¸€ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼ˆBonDNetï¼‰ã«é›†ç´„ |

### âœ… æ–°è¦è¿½åŠ ãƒ»å¤‰æ›´ã•ã‚ŒãŸæ©Ÿèƒ½

| é …ç›® | è©³ç´° |
|------|------|
| **BonDNet BDE-db2ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåŒ–** | 531,244ä»¶ã®BDEãƒ‡ãƒ¼ã‚¿ã§å†å­¦ç¿’ã—ãŸBonDNetã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«è¨­å®š |
| **Pure PyTorchç’°å¢ƒ** | TensorFlowä¾å­˜ã‚’å®Œå…¨å‰Šé™¤ã€‚PyTorch 2.10.0+ nightly (cu128) ã®ã¿ä½¿ç”¨ |
| **Phase 0ã®è¿½åŠ ** | BDE-db2ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰â†’BonDNetå†å­¦ç¿’ã‚’ãƒ‡ãƒ¼ã‚¿æº–å‚™å‰ã®å¿…é ˆãƒ•ã‚§ãƒ¼ã‚ºã¨ã—ã¦è¿½åŠ  |
| **ãƒãƒ­ã‚²ãƒ³ãƒ»ç¡«é»„ãƒ»ãƒªãƒ³å¯¾å¿œ** | BDE-db2ã«ã‚ˆã‚Š10å…ƒç´ ï¼ˆC,H,O,N,F,S,P,Cl,Br,Iï¼‰ã‚’ã‚µãƒãƒ¼ãƒˆ |
| **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç°¡ç´ åŒ–** | BonDNetå˜ä¸€ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰åŒ–ã«ã‚ˆã‚Š`config.yml`ã®BDEã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç°¡ç•¥åŒ– |

---

## ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦

### ç›®çš„

NIST 17 EI-MSãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆç´„300,000ã‚¹ãƒšã‚¯ãƒˆãƒ«ï¼‰ã‚’ç”¨ã„ã¦ã€**ç‰©ç†åŒ–å­¦çš„ã«è§£é‡ˆå¯èƒ½ãªGraph Neural Network**ã«ã‚ˆã‚‹EI-MSã‚¹ãƒšã‚¯ãƒˆãƒ«äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

### åŸºç›¤æŠ€è¡“

**QC-GN2oMS2**ï¼ˆPNNL, 2024ï¼‰:
- è«–æ–‡: "Quantum Chemistry-Informed Graph Neural Network for Mass Spectrum Prediction"
- ç‰¹å¾´: é‡å­åŒ–å­¦è¨ˆç®—ï¼ˆBDEï¼‰ã‚’ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ã¨ã—ã¦ä½¿ç”¨
- å…ƒã®å¯¾è±¡: MS/MSï¼ˆã‚¿ãƒ³ãƒ‡ãƒ è³ªé‡åˆ†æï¼‰
- **æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã®é©ç”¨**: EI-MSï¼ˆé›»å­ã‚¤ã‚ªãƒ³åŒ–è³ªé‡åˆ†æã€70eVå›ºå®šï¼‰

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦å›³

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 0: BDE-db2ç’°å¢ƒæ§‹ç¯‰ï¼ˆå¿…é ˆå‰å‡¦ç†ï¼‰                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. BDE-db2ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (531,244 reactions)                   â”‚
â”‚ 2. BonDNetå†å­¦ç¿’ (2-3æ—¥, RTX 5070 Ti)                        â”‚
â”‚ 3. å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ (MAE < 1.0 kcal/molç›®æ¨™)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 1: ãƒ‡ãƒ¼ã‚¿æº–å‚™                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ NIST 17 EI-MS â†’ BonDNet BDEè¨ˆç®— â†’ PyG Graph â†’ HDF5         â”‚
â”‚ (300,000 spectra Ã— 75 min = 5æ—¥é–“)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 2: GNNå­¦ç¿’                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 10-layer GATv2Conv + Residual Connections                   â”‚
â”‚ RTX 5070 Ti (16GB GDDR7) Ã— ç´„48æ™‚é–“                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 3: è©•ä¾¡                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Cosine Similarity, Top-10 Recall, Physical Interpretability â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ

### BDEè¨ˆç®—ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰: BonDNet (BDE-db2å†å­¦ç¿’ç‰ˆ)

#### é¸å®šç†ç”±

| åŸºæº– | BonDNet (BDE-db2) | ALFABET | xTB GPU |
|------|------------------|---------|---------|
| **ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯** | PyTorch âœ… | TensorFlow âŒ | Fortran (nvfortran) |
| **é€Ÿåº¦** | 15ms/åˆ†å­ âœ… | 5ms/åˆ†å­ | 1.5ç§’/åˆ†å­ âŒ |
| **ç²¾åº¦** | MAE 0.51 kcal/mol âœ… | MAE 0.45 kcal/mol | MAE 3-5 kcal/mol âŒ |
| **å¯¾å¿œå…ƒç´ ** | 10å…ƒç´  (BDE-db2) âœ… | 6å…ƒç´  | å…¨å…ƒç´  |
| **BDEç›´æ¥è¨ˆç®—** | å¯èƒ½ âœ… | å¯èƒ½ | ä¸å¯ï¼ˆã‚¨ãƒãƒ«ã‚®ãƒ¼å·®åˆ†æ³•ã®ã¿ï¼‰âŒ |
| **ç’°å¢ƒçµ±ä¸€æ€§** | PyTorchçµ±ä¸€ âœ… | TF/PyTorchæ··åœ¨ âŒ | åˆ¥ãƒ—ãƒ­ã‚»ã‚¹èµ·å‹• |
| **å­¦ç¿’ã‚³ã‚¹ãƒˆ** | 2-3æ—¥ (åˆå›ã®ã¿) | å­¦ç¿’æ¸ˆã¿ | N/A |

#### BDE-db2ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè©³ç´°

**Paton Group BDE-db2**:
- ç·ãƒ‡ãƒ¼ã‚¿æ•°: **531,244 BDEå€¤**
- å…ƒç´ ç¨®: C, H, O, N, F, S, P, Cl, Br, Iï¼ˆ10å…ƒç´ ï¼‰
- ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: B3LYP/6-31G(d) DFTè¨ˆç®—
- è«–æ–‡: "A comprehensive database of bond dissociation enthalpies" (Paton et al.)

**BDNCMï¼ˆBonDNetå…¬å¼ï¼‰ã¨ã®æ¯”è¼ƒ**:
| é …ç›® | BDNCM (å…¬å¼) | BDE-db2 (æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ) |
|------|-------------|------------------------|
| ãƒ‡ãƒ¼ã‚¿æ•° | 64,312 | 531,244 |
| å…ƒç´ æ•° | 5 (C,H,O,F,Li) | 10 (C,H,O,N,F,S,P,Cl,Br,I) |
| ç”¨é€” | æœ‰æ©Ÿãƒªãƒã‚¦ãƒ é›»æ±  | æ±ç”¨æœ‰æ©ŸåŒ–åˆç‰© âœ… |
| ãƒãƒ­ã‚²ãƒ³å¯¾å¿œ | Fã®ã¿ | Cl, Br, Iå¯¾å¿œ âœ… |

**NIST 17ã¨ã®é©åˆæ€§**:
- NIST 17ã®95%ä»¥ä¸ŠãŒ10å…ƒç´ å†…ã«åã¾ã‚‹
- ç’°çŠ¶åŒ–åˆç‰©ã€ãƒ˜ãƒ†ãƒ­ç’°åŒ–åˆç‰©ã®å¤šæ§˜æ€§ã«å¯¾å¿œ
- ãƒãƒ­ã‚²ãƒ³åŒ–åˆç‰©ï¼ˆè¾²è–¬ã€åŒ»è–¬å“ï¼‰ã®ã‚«ãƒãƒ¬ãƒƒã‚¸å‘ä¸Š

#### BonDNetå†å­¦ç¿’ã®å¿…è¦æ€§

BonDNetå…¬å¼ãƒ¢ãƒ‡ãƒ«ï¼ˆBDNCMå­¦ç¿’æ¸ˆã¿ï¼‰ã¯ä»¥ä¸‹ã®ç†ç”±ã§ä¸ååˆ†:

1. **å…ƒç´ ä¸è¶³**: S, P, Cl, Br, I ãŒæœªå¯¾å¿œ
2. **ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒ**: æœ‰æ©Ÿãƒªãƒã‚¦ãƒ é›»æ± ç”¨é€”ã«æœ€é©åŒ–ï¼ˆNIST EI-MSã¨ãƒ‰ãƒ¡ã‚¤ãƒ³ä¹–é›¢ï¼‰
3. **ç²¾åº¦**: BDE-db2ã§ã®å†å­¦ç¿’ã«ã‚ˆã‚Šã€NISTåˆ†å­ã«å¯¾ã™ã‚‹MAEæ”¹å–„ãŒæœŸå¾…ã•ã‚Œã‚‹

**å†å­¦ç¿’ã«ã‚ˆã‚‹æ”¹å–„ç›®æ¨™**:
- MAE: 0.51 kcal/mol â†’ **0.8 kcal/molä»¥ä¸‹**ï¼ˆBDE-db2å†å­¦ç¿’å¾Œï¼‰
- ã‚«ãƒãƒ¬ãƒƒã‚¸: 85% â†’ **95%ä»¥ä¸Š**ï¼ˆ10å…ƒç´ å¯¾å¿œã«ã‚ˆã‚Šï¼‰

---

### GNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: 10-layer GATv2Conv

#### ãƒ¢ãƒ‡ãƒ«æ§‹æˆ

```python
import torch
import torch.nn as nn
from torch_geometric.nn import GATv2Conv, global_mean_pool

class QCGN2oEI(nn.Module):
    """
    QC-GN2oMS2 Architecture for EI-MS Prediction

    Key changes from original:
    - MS/MS â†’ EI-MS (fragmentation energy: variable â†’ 70eV fixed)
    - Edge features: BDE from BonDNet (BDE-db2 retrained)
    - Output: 1000-bin intensity distribution (m/z 50-1000)
    """

    def __init__(
        self,
        node_dim: int = 128,       # Atom feature dimension
        edge_dim: int = 64,        # Edge feature dimension (includes BDE)
        hidden_dim: int = 256,     # Hidden layer dimension
        num_layers: int = 10,      # GATv2Conv layers
        num_heads: int = 8,        # Attention heads
        output_dim: int = 1000,    # Output spectrum bins
        dropout: float = 0.1
    ):
        super().__init__()

        # Node embedding
        self.node_encoder = nn.Sequential(
            nn.Linear(node_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout)
        )

        # Edge embedding (BDE + bond features)
        self.edge_encoder = nn.Sequential(
            nn.Linear(edge_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout)
        )

        # 10-layer GATv2Conv with residual connections
        self.gat_layers = nn.ModuleList()
        self.residual_layers = nn.ModuleList()

        for i in range(num_layers):
            # GATv2Conv layer
            self.gat_layers.append(
                GATv2Conv(
                    in_channels=hidden_dim,
                    out_channels=hidden_dim // num_heads,
                    heads=num_heads,
                    edge_dim=hidden_dim,  # Edge features
                    dropout=dropout,
                    concat=True,          # Concatenate heads
                    residual=True         # PyG 2.6.1+ feature
                )
            )

            # Residual connection projection
            self.residual_layers.append(
                nn.Linear(hidden_dim, hidden_dim)
            )

        # Global pooling + prediction head
        self.prediction_head = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim * 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, output_dim),
            nn.Softmax(dim=-1)  # Normalize to intensity distribution
        )

    def forward(self, data):
        """
        Args:
            data: PyG Data object
                - x: Node features [num_nodes, node_dim]
                - edge_index: Graph connectivity [2, num_edges]
                - edge_attr: Edge features (includes BDE) [num_edges, edge_dim]
                - batch: Batch assignment [num_nodes]

        Returns:
            spectrum: Predicted intensity [batch_size, 1000]
        """
        # Encode nodes and edges
        x = self.node_encoder(data.x)
        edge_attr = self.edge_encoder(data.edge_attr)

        # 10-layer GATv2Conv with residual connections
        for gat, residual in zip(self.gat_layers, self.residual_layers):
            x_res = residual(x)  # Residual projection
            x = gat(x, data.edge_index, edge_attr)
            x = x + x_res  # Residual addition
            x = torch.relu(x)

        # Global mean pooling
        x = global_mean_pool(x, data.batch)

        # Predict spectrum
        spectrum = self.prediction_head(x)

        return spectrum
```

#### ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ï¼ˆ128æ¬¡å…ƒï¼‰

| ã‚«ãƒ†ã‚´ãƒª | æ¬¡å…ƒ | å†…å®¹ |
|---------|------|------|
| **åŸå­ç¨®** | 10 | C, H, O, N, F, S, P, Cl, Br, I (one-hot) |
| **ãƒã‚¤ãƒ–ãƒªãƒ€ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³** | 5 | SP, SP2, SP3, SP3D, SP3D2 (one-hot) |
| **å½¢å¼é›»è·** | 3 | -1, 0, +1 (one-hot) |
| **èŠ³é¦™æ—æ€§** | 1 | Binary (aromatic/aliphatic) |
| **ç’°æ§‹é€ ** | 1 | Binary (in ring/not in ring) |
| **æ°´ç´ çµåˆæ•°** | 5 | 0, 1, 2, 3, 4+ (one-hot) |
| **æ¬¡æ•°ï¼ˆdegreeï¼‰** | 6 | 0, 1, 2, 3, 4, 5+ (one-hot) |
| **ãƒ©ã‚¸ã‚«ãƒ«é›»å­** | 3 | 0, 1, 2 (one-hot) |
| **ã‚­ãƒ©ãƒªãƒ†ã‚£** | 3 | None, R, S (one-hot) |
| **éƒ¨åˆ†é›»è·** | 1 | Gasteiger charge (continuous) |
| **åŸå­é‡** | 1 | Normalized atomic mass (continuous) |
| **ãƒ•ã‚¡ãƒ³ der WaalsåŠå¾„** | 1 | Normalized vdW radius (continuous) |
| **é›»æ°—é™°æ€§åº¦** | 1 | Pauling electronegativity (continuous) |
| **äºˆå‚™** | 87 | å°†æ¥ã®æ‹¡å¼µç”¨ |

**å®Ÿè£…ä¾‹**:
```python
from rdkit import Chem
from rdkit.Chem import Descriptors, rdMolDescriptors
import numpy as np

def get_atom_features(atom: Chem.Atom) -> np.ndarray:
    """Extract 128-dimensional atom features"""

    # Atom type (10-dim one-hot)
    atom_types = ['C', 'H', 'O', 'N', 'F', 'S', 'P', 'Cl', 'Br', 'I']
    atom_type = one_hot(atom.GetSymbol(), atom_types)

    # Hybridization (5-dim one-hot)
    hybridizations = [
        Chem.HybridizationType.SP,
        Chem.HybridizationType.SP2,
        Chem.HybridizationType.SP3,
        Chem.HybridizationType.SP3D,
        Chem.HybridizationType.SP3D2
    ]
    hybrid = one_hot(atom.GetHybridization(), hybridizations)

    # Formal charge (3-dim one-hot)
    charge = one_hot(atom.GetFormalCharge(), [-1, 0, 1])

    # Binary features
    aromatic = [int(atom.GetIsAromatic())]
    in_ring = [int(atom.IsInRing())]

    # Hydrogen count (5-dim one-hot)
    num_h = one_hot(atom.GetTotalNumHs(), [0, 1, 2, 3, 4])

    # Degree (6-dim one-hot)
    degree = one_hot(atom.GetDegree(), [0, 1, 2, 3, 4, 5])

    # Radical electrons (3-dim one-hot)
    radical = one_hot(atom.GetNumRadicalElectrons(), [0, 1, 2])

    # Chirality (3-dim one-hot)
    chiralities = [
        Chem.ChiralType.CHI_UNSPECIFIED,
        Chem.ChiralType.CHI_TETRAHEDRAL_CW,
        Chem.ChiralType.CHI_TETRAHEDRAL_CCW
    ]
    chirality = one_hot(atom.GetChiralTag(), chiralities)

    # Continuous features
    partial_charge = [atom.GetDoubleProp('_GasteigerCharge') if atom.HasProp('_GasteigerCharge') else 0.0]
    atomic_mass = [atom.GetMass() / 100.0]  # Normalize
    vdw_radius = [Chem.GetPeriodicTable().GetRvdw(atom.GetSymbol()) / 2.0]  # Normalize
    electronegativity = [Chem.GetPeriodicTable().GetElectronegativity(atom.GetSymbol()) / 4.0]  # Normalize

    # Concatenate (total: 10+5+3+1+1+5+6+3+3+1+1+1+1 = 41 dims)
    # Pad to 128 with zeros
    features = np.concatenate([
        atom_type, hybrid, charge, aromatic, in_ring,
        num_h, degree, radical, chirality,
        partial_charge, atomic_mass, vdw_radius, electronegativity
    ])

    padded = np.zeros(128)
    padded[:len(features)] = features

    return padded

def one_hot(value, choices):
    """One-hot encoding with out-of-vocabulary handling"""
    encoding = [0] * len(choices)
    if value in choices:
        encoding[choices.index(value)] = 1
    return encoding
```

#### ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ï¼ˆ64æ¬¡å…ƒï¼‰

| ã‚«ãƒ†ã‚´ãƒª | æ¬¡å…ƒ | å†…å®¹ |
|---------|------|------|
| **BDEï¼ˆé‡è¦ï¼‰** | 1 | Bond Dissociation Energy from BonDNet (kcal/mol, normalized) |
| **çµåˆæ¬¡æ•°** | 4 | Single, Double, Triple, Aromatic (one-hot) |
| **ç’°å†…çµåˆ** | 1 | Binary (in ring/not in ring) |
| **å…±å½¹** | 1 | Binary (conjugated/not conjugated) |
| **ç«‹ä½“åŒ–å­¦** | 3 | None, E, Z (one-hot) |
| **å›è»¢å¯èƒ½æ€§** | 1 | Binary (rotatable/rigid) |
| **çµåˆè·é›¢** | 1 | Normalized bond length (Ã…) |
| **äºˆå‚™** | 52 | å°†æ¥ã®æ‹¡å¼µç”¨ |

**BDEæ­£è¦åŒ–**:
```python
def normalize_bde(bde_kcal_mol: float) -> float:
    """
    Normalize BDE to [0, 1] range

    Typical BDE ranges:
    - C-C single: 85 kcal/mol
    - C=C double: 146 kcal/mol
    - C-H: 105 kcal/mol
    - O-H: 110 kcal/mol
    - Aromatic C-C: 120 kcal/mol

    Range: 50-200 kcal/mol
    """
    return (bde_kcal_mol - 50.0) / 150.0
```

**å®Ÿè£…ä¾‹**:
```python
def get_bond_features(bond: Chem.Bond, bde_value: float) -> np.ndarray:
    """Extract 64-dimensional bond features"""

    # BDE (normalized)
    bde = [normalize_bde(bde_value)]

    # Bond type (4-dim one-hot)
    bond_types = [
        Chem.BondType.SINGLE,
        Chem.BondType.DOUBLE,
        Chem.BondType.TRIPLE,
        Chem.BondType.AROMATIC
    ]
    bond_type = one_hot(bond.GetBondType(), bond_types)

    # Binary features
    in_ring = [int(bond.IsInRing())]
    conjugated = [int(bond.GetIsConjugated())]

    # Stereochemistry (3-dim one-hot)
    stereo = one_hot(bond.GetStereo(), [
        Chem.BondStereo.STEREONONE,
        Chem.BondStereo.STEREOE,
        Chem.BondStereo.STEREOZ
    ])

    # Rotatable
    rotatable = [int(bond.GetBondDir() == Chem.BondDir.NONE and not bond.IsInRing())]

    # Bond length (requires 3D conformer)
    mol = bond.GetOwningMol()
    if mol.GetNumConformers() > 0:
        conf = mol.GetConformer()
        pos_i = conf.GetAtomPosition(bond.GetBeginAtomIdx())
        pos_j = conf.GetAtomPosition(bond.GetEndAtomIdx())
        length = [(pos_i - pos_j).Length() / 2.0]  # Normalize to ~[0, 1]
    else:
        length = [0.75]  # Default typical bond length

    # Concatenate (total: 1+4+1+1+3+1+1 = 12 dims)
    # Pad to 64 with zeros
    features = np.concatenate([
        bde, bond_type, in_ring, conjugated, stereo, rotatable, length
    ])

    padded = np.zeros(64)
    padded[:len(features)] = features

    return padded
```

---

## Phase 0: BDE-db2ç’°å¢ƒæ§‹ç¯‰

### æ¦‚è¦

BonDNetã‚’BDE-db2ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å†å­¦ç¿’ã—ã€NIST 17åˆ†å­ã«æœ€é©åŒ–ã•ã‚ŒãŸBDEãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

### ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³

| ã‚¹ãƒ†ãƒƒãƒ— | æ¨å®šæ™‚é–“ | è©³ç´° |
|---------|---------|------|
| **0.1 BDE-db2ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰** | 30åˆ† | GitHub LFSçµŒç”±ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆç´„50GBï¼‰ |
| **0.2 ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†** | 3æ™‚é–“ | BonDNetå½¢å¼ã¸ã®å¤‰æ›ã€train/val/teståˆ†å‰² |
| **0.3 BonDNetå†å­¦ç¿’** | 48-72æ™‚é–“ | RTX 5070 Ti Ã— 531,244ã‚µãƒ³ãƒ—ãƒ« |
| **0.4 ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼** | 1æ™‚é–“ | MAEè¨ˆç®—ã€ã‚¨ãƒ©ãƒ¼åˆ†æ |
| **åˆè¨ˆ** | **2-3æ—¥** | - |

### 0.1 BDE-db2ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

```bash
#!/bin/bash
# scripts/download_bde_db2.sh

set -e

echo "Downloading BDE-db2 dataset..."

# Create directory
mkdir -p data/external/bde-db2

# Clone BDE-db2 repository
cd data/external/bde-db2
git clone https://github.com/patongroup/BDE-db2.git .

# Verify download
if [ -f "bde_data.csv" ]; then
    echo "âœ… BDE-db2 downloaded successfully"
    wc -l bde_data.csv
else
    echo "âŒ Download failed"
    exit 1
fi
```

**ãƒ‡ãƒ¼ã‚¿å½¢å¼**:
```csv
smiles,bond_index_1,bond_index_2,bde_kcal_mol,method,basis_set
CCO,0,1,85.3,B3LYP,6-31G(d)
CCO,1,2,104.2,B3LYP,6-31G(d)
c1ccccc1,0,1,119.8,B3LYP,6-31G(d)
...
```

### 0.2 ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†

```python
# scripts/preprocess_bde_db2.py
"""
Convert BDE-db2 to BonDNet training format
"""

import pandas as pd
import numpy as np
from rdkit import Chem
from bondnet.data.dataset import prepare_reaction_graphs
import pickle
from pathlib import Path

def convert_bde_db2_to_bondnet(
    input_csv: str = "data/external/bde-db2/bde_data.csv",
    output_dir: str = "data/processed/bondnet_bde_db2"
):
    """
    Convert BDE-db2 CSV to BonDNet graph format

    BonDNet expects reaction SMILES: reactant>>product
    For BDE: parent_molecule >> radical1.radical2
    """

    print("Loading BDE-db2...")
    df = pd.read_csv(input_csv)
    print(f"Total entries: {len(df)}")

    # Filter valid SMILES
    df = df[df['smiles'].apply(lambda x: Chem.MolFromSmiles(x) is not None)]
    print(f"Valid SMILES: {len(df)}")

    # Create reaction SMILES for BonDNet
    reactions = []
    bde_values = []

    for idx, row in df.iterrows():
        smiles = row['smiles']
        bond_idx_1 = int(row['bond_index_1'])
        bond_idx_2 = int(row['bond_index_2'])
        bde = float(row['bde_kcal_mol'])

        # Create fragmented SMILES
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            continue

        # Fragment at specified bond
        frag = Chem.FragmentOnBonds(
            mol,
            [mol.GetBondBetweenAtoms(bond_idx_1, bond_idx_2).GetIdx()],
            addDummies=False
        )

        # Get fragment SMILES
        frags = Chem.GetMolFrags(frag, asMols=True)
        if len(frags) != 2:
            continue

        frag1_smi = Chem.MolToSmiles(frags[0])
        frag2_smi = Chem.MolToSmiles(frags[1])

        # Reaction format: parent >> radical1.radical2
        reaction_smi = f"{smiles}>>{frag1_smi}.{frag2_smi}"

        reactions.append(reaction_smi)
        bde_values.append(bde)

        if idx % 10000 == 0:
            print(f"Processed {idx}/{len(df)}")

    print(f"Total reactions: {len(reactions)}")

    # Train/Val/Test split (80/10/10)
    np.random.seed(42)
    indices = np.random.permutation(len(reactions))

    n_train = int(0.8 * len(reactions))
    n_val = int(0.1 * len(reactions))

    train_idx = indices[:n_train]
    val_idx = indices[n_train:n_train+n_val]
    test_idx = indices[n_train+n_val:]

    # Create BonDNet datasets
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    for split, idx in [('train', train_idx), ('val', val_idx), ('test', test_idx)]:
        split_reactions = [reactions[i] for i in idx]
        split_bde = [bde_values[i] for i in idx]

        # Save as BonDNet format
        dataset = prepare_reaction_graphs(split_reactions, split_bde)

        with open(output_path / f"{split}.pkl", 'wb') as f:
            pickle.dump(dataset, f)

        print(f"{split}: {len(split_reactions)} reactions")

    print("âœ… BDE-db2 conversion complete")

if __name__ == "__main__":
    convert_bde_db2_to_bondnet()
```

**å®Ÿè¡Œ**:
```bash
python scripts/preprocess_bde_db2.py
```

**å‡ºåŠ›**:
```
data/processed/bondnet_bde_db2/
â”œâ”€â”€ train.pkl  (424,995 reactions)
â”œâ”€â”€ val.pkl    (53,125 reactions)
â””â”€â”€ test.pkl   (53,124 reactions)
```

### 0.3 BonDNetå†å­¦ç¿’

```python
# scripts/train_bondnet_bde_db2.py
"""
Train BonDNet on BDE-db2 dataset
"""

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from bondnet.model.gated_reaction_network import GatedGCNReactionNetwork
from bondnet.data.dataloader import DataLoaderReaction
import yaml
from pathlib import Path
import wandb

def train_bondnet_bde_db2(
    config_path: str = "config/bondnet_training.yml"
):
    """
    Train BonDNet on BDE-db2 dataset

    Expected training time: 48-72 hours on RTX 5070 Ti
    """

    # Load config
    with open(config_path) as f:
        config = yaml.safe_load(f)

    # Initialize wandb
    wandb.init(
        project="bondnet-bde-db2",
        config=config
    )

    # Device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

    # Data loaders
    train_loader = DataLoaderReaction(
        dataset_path="data/processed/bondnet_bde_db2/train.pkl",
        batch_size=config['training']['batch_size'],
        shuffle=True,
        num_workers=4
    )

    val_loader = DataLoaderReaction(
        dataset_path="data/processed/bondnet_bde_db2/val.pkl",
        batch_size=config['training']['batch_size'],
        shuffle=False,
        num_workers=4
    )

    # Model
    model = GatedGCNReactionNetwork(
        in_feats=config['model']['in_feats'],
        embedding_size=config['model']['embedding_size'],
        gated_num_layers=config['model']['gated_num_layers'],
        gated_hidden_size=config['model']['gated_hidden_size'],
        gated_num_fc_layers=config['model']['gated_num_fc_layers'],
        gated_graph_norm=config['model']['gated_graph_norm'],
        gated_batch_norm=config['model']['gated_batch_norm'],
        gated_activation=config['model']['gated_activation'],
        gated_residual=config['model']['gated_residual'],
        gated_dropout=config['model']['gated_dropout'],
        num_lstm_iters=config['model']['num_lstm_iters'],
        num_lstm_layers=config['model']['num_lstm_layers'],
        set2set_ntypes_direct=config['model']['set2set_ntypes_direct'],
        fc_num_layers=config['model']['fc_num_layers'],
        fc_hidden_size=config['model']['fc_hidden_size'],
        fc_batch_norm=config['model']['fc_batch_norm'],
        fc_activation=config['model']['fc_activation'],
        fc_dropout=config['model']['fc_dropout'],
    ).to(device)

    print(f"Model parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")

    # Optimizer & Scheduler
    optimizer = torch.optim.Adam(
        model.parameters(),
        lr=config['training']['learning_rate'],
        weight_decay=config['training']['weight_decay']
    )

    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer,
        mode='min',
        factor=0.5,
        patience=10,
        verbose=True
    )

    # Loss function
    criterion = nn.L1Loss()  # MAE loss

    # Training loop
    best_val_mae = float('inf')

    for epoch in range(config['training']['num_epochs']):
        # Train
        model.train()
        train_loss = 0.0

        for batch in train_loader:
            batch = batch.to(device)

            optimizer.zero_grad()
            pred = model(batch)
            loss = criterion(pred, batch.y)
            loss.backward()
            optimizer.step()

            train_loss += loss.item()

        train_loss /= len(train_loader)

        # Validation
        model.eval()
        val_loss = 0.0

        with torch.no_grad():
            for batch in val_loader:
                batch = batch.to(device)
                pred = model(batch)
                loss = criterion(pred, batch.y)
                val_loss += loss.item()

        val_loss /= len(val_loader)

        # Learning rate scheduling
        scheduler.step(val_loss)

        # Logging
        wandb.log({
            'epoch': epoch,
            'train_mae': train_loss,
            'val_mae': val_loss,
            'learning_rate': optimizer.param_groups[0]['lr']
        })

        print(f"Epoch {epoch+1}/{config['training']['num_epochs']}: "
              f"Train MAE={train_loss:.4f}, Val MAE={val_loss:.4f}")

        # Save best model
        if val_loss < best_val_mae:
            best_val_mae = val_loss
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_mae': val_loss,
            }, "models/bondnet_bde_db2_best.pth")
            print(f"âœ… Best model saved (Val MAE: {val_loss:.4f})")

    print(f"Training complete. Best Val MAE: {best_val_mae:.4f}")

if __name__ == "__main__":
    train_bondnet_bde_db2()
```

**è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«**:
```yaml
# config/bondnet_training.yml

model:
  in_feats: 54  # Atom feature dimension
  embedding_size: 128
  gated_num_layers: 4
  gated_hidden_size: [128, 128, 64]
  gated_num_fc_layers: 2
  gated_graph_norm: True
  gated_batch_norm: True
  gated_activation: "ReLU"
  gated_residual: True
  gated_dropout: 0.0
  num_lstm_iters: 6
  num_lstm_layers: 3
  set2set_ntypes_direct: ["atom", "bond", "global"]
  fc_num_layers: 2
  fc_hidden_size: [64, 32]
  fc_batch_norm: False
  fc_activation: "ReLU"
  fc_dropout: 0.0

training:
  num_epochs: 200
  batch_size: 256  # RTX 5070 Ti (16GB) optimal batch size
  learning_rate: 0.001
  weight_decay: 0.0
  early_stopping_patience: 30
```

**å®Ÿè¡Œ**:
```bash
python scripts/train_bondnet_bde_db2.py
```

**äºˆæƒ³å‡ºåŠ›ï¼ˆ48æ™‚é–“å¾Œï¼‰**:
```
Epoch 200/200: Train MAE=0.612, Val MAE=0.784
âœ… Best model saved (Val MAE: 0.784)
Training complete. Best Val MAE: 0.784
```

### 0.4 ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼

```python
# scripts/evaluate_bondnet_bde_db2.py
"""
Evaluate trained BonDNet model
"""

import torch
from bondnet.model.gated_reaction_network import GatedGCNReactionNetwork
from bondnet.data.dataloader import DataLoaderReaction
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def evaluate_bondnet(
    model_path: str = "models/bondnet_bde_db2_best.pth",
    test_data: str = "data/processed/bondnet_bde_db2/test.pkl"
):
    """Evaluate BonDNet on test set"""

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # Load model
    checkpoint = torch.load(model_path)
    model = GatedGCNReactionNetwork(...)  # Same config as training
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()

    # Test loader
    test_loader = DataLoaderReaction(
        dataset_path=test_data,
        batch_size=256,
        shuffle=False
    )

    # Inference
    predictions = []
    targets = []

    with torch.no_grad():
        for batch in test_loader:
            batch = batch.to(device)
            pred = model(batch)
            predictions.extend(pred.cpu().numpy())
            targets.extend(batch.y.cpu().numpy())

    predictions = np.array(predictions)
    targets = np.array(targets)

    # Metrics
    mae = np.mean(np.abs(predictions - targets))
    rmse = np.sqrt(np.mean((predictions - targets) ** 2))
    r2 = 1 - np.sum((predictions - targets) ** 2) / np.sum((targets - np.mean(targets)) ** 2)

    print("=" * 60)
    print("BonDNet BDE-db2 Test Results")
    print("=" * 60)
    print(f"MAE:  {mae:.4f} kcal/mol")
    print(f"RMSE: {rmse:.4f} kcal/mol")
    print(f"RÂ²:   {r2:.4f}")
    print("=" * 60)

    # Visualization
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))

    # Parity plot
    axes[0].scatter(targets, predictions, alpha=0.3, s=1)
    axes[0].plot([targets.min(), targets.max()], [targets.min(), targets.max()], 'r--')
    axes[0].set_xlabel("True BDE (kcal/mol)")
    axes[0].set_ylabel("Predicted BDE (kcal/mol)")
    axes[0].set_title(f"Parity Plot (RÂ²={r2:.4f})")

    # Error distribution
    errors = predictions - targets
    axes[1].hist(errors, bins=50, alpha=0.7)
    axes[1].axvline(0, color='r', linestyle='--')
    axes[1].set_xlabel("Prediction Error (kcal/mol)")
    axes[1].set_ylabel("Count")
    axes[1].set_title(f"Error Distribution (MAE={mae:.4f})")

    plt.tight_layout()
    plt.savefig("results/bondnet_bde_db2_evaluation.png", dpi=300)
    print("âœ… Evaluation plot saved to results/bondnet_bde_db2_evaluation.png")

if __name__ == "__main__":
    evaluate_bondnet()
```

**ç›®æ¨™ç²¾åº¦**:
- MAE < 0.8 kcal/mol
- RMSE < 1.5 kcal/mol
- RÂ² > 0.95

---

## Phase 1: ãƒ‡ãƒ¼ã‚¿æº–å‚™

### 1.1 NIST 17ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿

```python
# src/data/nist_loader.py
"""
NIST 17 EI-MS Data Loader
"""

import pandas as pd
import numpy as np
from rdkit import Chem
from pathlib import Path
from typing import List, Dict, Tuple

class NIST17Loader:
    """
    NIST 17 EI-MS Database Loader

    Expected format: MSP file with NIST spectra
    """

    def __init__(self, nist_path: str = "data/external/nist17/mainlib"):
        self.nist_path = Path(nist_path)

    def parse_msp(self, msp_file: str) -> List[Dict]:
        """
        Parse NIST MSP file

        Returns:
            List of dicts with keys: name, smiles, spectrum
        """
        spectra = []
        current_spectrum = {}
        current_peaks = []

        with open(msp_file, 'r', encoding='utf-8', errors='ignore') as f:
            for line in f:
                line = line.strip()

                if line.startswith("Name:"):
                    if current_spectrum:
                        current_spectrum['spectrum'] = current_peaks
                        spectra.append(current_spectrum)
                    current_spectrum = {'name': line.split(":", 1)[1].strip()}
                    current_peaks = []

                elif line.startswith("SMILES:"):
                    current_spectrum['smiles'] = line.split(":", 1)[1].strip()

                elif line.startswith("Num Peaks:"):
                    num_peaks = int(line.split(":")[1].strip())

                elif line and line[0].isdigit():
                    # Peak data: "m/z intensity; m/z intensity; ..."
                    for peak in line.split(";"):
                        peak = peak.strip()
                        if peak:
                            mz, intensity = peak.split()
                            current_peaks.append((int(mz), int(intensity)))

        # Add last spectrum
        if current_spectrum:
            current_spectrum['spectrum'] = current_peaks
            spectra.append(current_spectrum)

        return spectra

    def load_all_spectra(self) -> pd.DataFrame:
        """Load all NIST 17 spectra into DataFrame"""

        all_spectra = []

        # NIST 17 has multiple MSP files
        msp_files = list(self.nist_path.glob("*.msp"))

        for msp_file in msp_files:
            print(f"Loading {msp_file.name}...")
            spectra = self.parse_msp(msp_file)
            all_spectra.extend(spectra)

        df = pd.DataFrame(all_spectra)

        # Filter valid SMILES
        df = df[df['smiles'].notna()]
        df = df[df['smiles'].apply(lambda x: Chem.MolFromSmiles(x) is not None)]

        print(f"Total spectra: {len(df)}")

        return df

    def spectrum_to_array(self, peaks: List[Tuple[int, int]],
                          mz_range: Tuple[int, int] = (50, 1000)) -> np.ndarray:
        """
        Convert peak list to fixed-size array

        Args:
            peaks: List of (m/z, intensity) tuples
            mz_range: (min_mz, max_mz)

        Returns:
            spectrum_array: [950] array for m/z 50-1000
        """
        min_mz, max_mz = mz_range
        spectrum = np.zeros(max_mz - min_mz)

        for mz, intensity in peaks:
            if min_mz <= mz < max_mz:
                spectrum[mz - min_mz] = intensity

        # Normalize to [0, 1]
        if spectrum.max() > 0:
            spectrum = spectrum / spectrum.max()

        return spectrum
```

### 1.2 BDEå‰è¨ˆç®—ï¼ˆBonDNet BDE-db2ï¼‰

```python
# src/data/bde_calculator.py
"""
BDE Calculation using BonDNet (BDE-db2 retrained model)
"""

import torch
import numpy as np
from rdkit import Chem
from bondnet.model.gated_reaction_network import GatedGCNReactionNetwork
from bondnet.prediction.predictor import predict_single_molecule
from typing import Dict
import h5py
from pathlib import Path

class BDECalculator:
    """
    Bond Dissociation Energy Calculator

    Uses BonDNet model retrained on BDE-db2 dataset
    """

    def __init__(
        self,
        model_path: str = "models/bondnet_bde_db2_best.pth",
        device: str = "cuda"
    ):
        self.device = torch.device(device if torch.cuda.is_available() else "cpu")

        # Load BonDNet model
        checkpoint = torch.load(model_path, map_location=self.device)
        self.model = GatedGCNReactionNetwork(...)  # Config from training
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(self.device)
        self.model.eval()

        print(f"âœ… BonDNet model loaded from {model_path}")
        print(f"   Using device: {self.device}")

    def calculate_bde(self, smiles: str, charge: int = 0) -> Dict[int, float]:
        """
        Calculate BDE for all bonds in a molecule

        Args:
            smiles: SMILES string
            charge: Molecular charge (default: 0)

        Returns:
            bde_dict: {bond_idx: bde_value (kcal/mol)}
        """
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            return {}

        bde_dict = {}

        with torch.no_grad():
            for bond in mol.GetBonds():
                bond_idx = bond.GetIdx()
                atom_i = bond.GetBeginAtomIdx()
                atom_j = bond.GetEndAtomIdx()

                # Create reaction SMILES for BonDNet
                frag = Chem.FragmentOnBonds(mol, [bond_idx], addDummies=False)
                frags = Chem.GetMolFrags(frag, asMols=True)

                if len(frags) != 2:
                    # Cyclic bond: use default estimate
                    if bond.GetIsAromatic():
                        bde_dict[bond_idx] = 120.0  # Aromatic C-C
                    else:
                        bde_dict[bond_idx] = 85.0   # Aliphatic C-C in ring
                    continue

                frag1_smi = Chem.MolToSmiles(frags[0])
                frag2_smi = Chem.MolToSmiles(frags[1])
                reaction_smi = f"{smiles}>>{frag1_smi}.{frag2_smi}"

                # Predict BDE using BonDNet
                try:
                    bde_pred = predict_single_molecule(
                        self.model,
                        reaction_smi,
                        charge=charge,
                        device=self.device
                    )
                    bde_dict[bond_idx] = float(bde_pred)
                except Exception as e:
                    # Fallback to rule-based estimate
                    bond_type = bond.GetBondType()
                    if bond_type == Chem.BondType.SINGLE:
                        bde_dict[bond_idx] = 85.0
                    elif bond_type == Chem.BondType.DOUBLE:
                        bde_dict[bond_idx] = 146.0
                    elif bond_type == Chem.BondType.TRIPLE:
                        bde_dict[bond_idx] = 200.0
                    else:
                        bde_dict[bond_idx] = 100.0

        return bde_dict

    def batch_calculate(
        self,
        smiles_list: list,
        output_hdf5: str = "data/processed/bde_cache.h5",
        batch_size: int = 64
    ):
        """
        Batch BDE calculation with HDF5 caching

        Args:
            smiles_list: List of SMILES strings
            output_hdf5: Output HDF5 file path
            batch_size: Batch size for GPU inference
        """
        from tqdm import tqdm

        Path(output_hdf5).parent.mkdir(parents=True, exist_ok=True)

        with h5py.File(output_hdf5, 'w') as f:
            for i, smiles in enumerate(tqdm(smiles_list, desc="Calculating BDE")):
                bde_dict = self.calculate_bde(smiles)

                # Store in HDF5
                grp = f.create_group(str(i))
                grp.attrs['smiles'] = smiles

                for bond_idx, bde_value in bde_dict.items():
                    grp.create_dataset(str(bond_idx), data=bde_value)

                if (i + 1) % 1000 == 0:
                    f.flush()

        print(f"âœ… BDE calculation complete: {output_hdf5}")
```

**å®Ÿè¡Œæ™‚é–“è¦‹ç©ã‚‚ã‚Š**:
```
300,000 molecules Ã— 15ms/molecule = 4,500 seconds = 75 minutes
```

### 1.3 PyG Graphç”Ÿæˆ

```python
# src/data/graph_generator.py
"""
PyTorch Geometric Graph Generator
"""

import torch
from torch_geometric.data import Data
from rdkit import Chem
from rdkit.Chem import AllChem, Descriptors
import numpy as np
from typing import Dict, List
import h5py

class GraphGenerator:
    """Generate PyTorch Geometric graphs with BDE edge features"""

    def __init__(self, bde_cache_path: str = "data/processed/bde_cache.h5"):
        self.bde_cache = h5py.File(bde_cache_path, 'r')

    def smiles_to_graph(
        self,
        smiles: str,
        spectrum: np.ndarray,
        molecule_idx: int
    ) -> Data:
        """
        Convert SMILES to PyG Data object

        Args:
            smiles: SMILES string
            spectrum: Target spectrum [1000]
            molecule_idx: Index for BDE cache lookup

        Returns:
            PyG Data object
        """
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            return None

        # Add hydrogens for complete graph
        mol = Chem.AddHs(mol)

        # Generate 3D conformer for bond lengths
        AllChem.EmbedMolecule(mol, randomSeed=42)
        AllChem.MMFFOptimizeMolecule(mol)

        # Compute Gasteiger charges
        AllChem.ComputeGasteigerCharges(mol)

        # Get BDE values from cache
        bde_dict = {}
        if str(molecule_idx) in self.bde_cache:
            grp = self.bde_cache[str(molecule_idx)]
            for bond_idx in grp.keys():
                bde_dict[int(bond_idx)] = float(grp[bond_idx][()])

        # Node features
        node_features = []
        for atom in mol.GetAtoms():
            node_features.append(self.get_atom_features(atom))

        x = torch.tensor(node_features, dtype=torch.float)

        # Edge features
        edge_index = []
        edge_attr = []

        for bond in mol.GetBonds():
            i = bond.GetBeginAtomIdx()
            j = bond.GetEndAtomIdx()
            bond_idx = bond.GetIdx()

            # Get BDE value
            bde_value = bde_dict.get(bond_idx, 100.0)  # Default if not in cache

            # Bidirectional edges
            edge_index.append([i, j])
            edge_index.append([j, i])

            bond_features = self.get_bond_features(bond, bde_value)
            edge_attr.append(bond_features)
            edge_attr.append(bond_features)  # Same features for both directions

        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
        edge_attr = torch.tensor(edge_attr, dtype=torch.float)

        # Target spectrum
        y = torch.tensor(spectrum, dtype=torch.float)

        # Create PyG Data
        data = Data(
            x=x,
            edge_index=edge_index,
            edge_attr=edge_attr,
            y=y,
            smiles=smiles
        )

        return data

    def get_atom_features(self, atom: Chem.Atom) -> List[float]:
        """Extract 128-dimensional atom features"""
        # (Implementation same as in architecture section)
        pass

    def get_bond_features(self, bond: Chem.Bond, bde_value: float) -> List[float]:
        """Extract 64-dimensional bond features"""
        # (Implementation same as in architecture section)
        pass
```

### 1.4 HDF5ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¿å­˜

```python
# scripts/prepare_dataset.py
"""
Prepare complete dataset with BDE and PyG graphs
"""

from src.data.nist_loader import NIST17Loader
from src.data.bde_calculator import BDECalculator
from src.data.graph_generator import GraphGenerator
import h5py
from pathlib import Path
from tqdm import tqdm

def prepare_full_dataset():
    """
    Full pipeline: NIST â†’ BDE â†’ PyG Graph â†’ HDF5
    """

    # Step 1: Load NIST 17
    print("Step 1: Loading NIST 17 data...")
    nist_loader = NIST17Loader("data/external/nist17/mainlib")
    df = nist_loader.load_all_spectra()
    print(f"Loaded {len(df)} spectra")

    # Step 2: Calculate BDE for all molecules
    print("\nStep 2: Calculating BDE (BonDNet BDE-db2)...")
    bde_calc = BDECalculator(
        model_path="models/bondnet_bde_db2_best.pth",
        device="cuda"
    )
    bde_calc.batch_calculate(
        smiles_list=df['smiles'].tolist(),
        output_hdf5="data/processed/bde_cache.h5"
    )

    # Step 3: Generate PyG graphs
    print("\nStep 3: Generating PyG graphs...")
    graph_gen = GraphGenerator("data/processed/bde_cache.h5")

    graphs = []
    for idx, row in tqdm(df.iterrows(), total=len(df)):
        spectrum_array = nist_loader.spectrum_to_array(row['spectrum'])
        graph = graph_gen.smiles_to_graph(
            smiles=row['smiles'],
            spectrum=spectrum_array,
            molecule_idx=idx
        )
        if graph is not None:
            graphs.append(graph)

    # Step 4: Train/Val/Test split
    print("\nStep 4: Splitting dataset...")
    from sklearn.model_selection import train_test_split

    train_graphs, temp_graphs = train_test_split(graphs, test_size=0.2, random_state=42)
    val_graphs, test_graphs = train_test_split(temp_graphs, test_size=0.5, random_state=42)

    print(f"Train: {len(train_graphs)}, Val: {len(val_graphs)}, Test: {len(test_graphs)}")

    # Step 5: Save to HDF5
    print("\nStep 5: Saving to HDF5...")
    import torch

    for split, split_graphs in [('train', train_graphs), ('val', val_graphs), ('test', test_graphs)]:
        output_path = f"data/processed/nist17_{split}.pt"
        torch.save(split_graphs, output_path)
        print(f"âœ… Saved {split}: {output_path}")

    print("\nâœ… Dataset preparation complete!")

if __name__ == "__main__":
    prepare_full_dataset()
```

**å®Ÿè¡Œ**:
```bash
python scripts/prepare_dataset.py
```

**æ¨å®šæ™‚é–“**:
- NISTèª­ã¿è¾¼ã¿: 30åˆ†
- BDEè¨ˆç®—: 75åˆ†
- PyG Graphç”Ÿæˆ: 60åˆ†
- **åˆè¨ˆ: ç´„3æ™‚é–“**

---

## Phase 2: GNNå­¦ç¿’

### 2.1 å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```python
# scripts/train_gnn.py
"""
Train QC-GN2oEI model
"""

import torch
import torch.nn as nn
from torch_geometric.loader import DataLoader
from src.models.qcgn2oei import QCGN2oEI
import wandb
import yaml
from pathlib import Path
from tqdm import tqdm

def cosine_similarity_loss(pred, target):
    """
    Cosine Similarity Loss

    Same as QC-GN2oMS2 paper
    """
    pred_norm = pred / (pred.norm(dim=1, keepdim=True) + 1e-8)
    target_norm = target / (target.norm(dim=1, keepdim=True) + 1e-8)

    cosine_sim = (pred_norm * target_norm).sum(dim=1)

    # Return 1 - cosine_similarity (minimize loss)
    return (1 - cosine_sim).mean()

def train_qcgn2oei(config_path: str = "config/training.yml"):
    """Train QC-GN2oEI model"""

    # Load config
    with open(config_path) as f:
        config = yaml.safe_load(f)

    # Initialize wandb
    wandb.init(project="qcgn2oei", config=config)

    # Device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    # Data loaders
    train_data = torch.load("data/processed/nist17_train.pt")
    val_data = torch.load("data/processed/nist17_val.pt")

    train_loader = DataLoader(
        train_data,
        batch_size=config['training']['batch_size'],
        shuffle=True,
        num_workers=4
    )

    val_loader = DataLoader(
        val_data,
        batch_size=config['training']['batch_size'],
        shuffle=False,
        num_workers=4
    )

    # Model
    model = QCGN2oEI(
        node_dim=config['model']['node_dim'],
        edge_dim=config['model']['edge_dim'],
        hidden_dim=config['model']['hidden_dim'],
        num_layers=config['model']['num_layers'],
        num_heads=config['model']['num_heads'],
        output_dim=config['model']['output_dim'],
        dropout=config['model']['dropout']
    ).to(device)

    print(f"Model parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")

    # Optimizer (RAdam from QC-GN2oMS2)
    optimizer = torch.optim.RAdam(
        model.parameters(),
        lr=config['training']['learning_rate'],
        weight_decay=config['training']['weight_decay']
    )

    # Learning rate scheduler
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=config['training']['num_epochs'],
        eta_min=1e-6
    )

    # Training loop
    best_val_loss = float('inf')

    for epoch in range(config['training']['num_epochs']):
        # Train
        model.train()
        train_loss = 0.0

        for batch in tqdm(train_loader, desc=f"Epoch {epoch+1} [Train]"):
            batch = batch.to(device)

            optimizer.zero_grad()
            pred = model(batch)
            loss = cosine_similarity_loss(pred, batch.y)
            loss.backward()
            optimizer.step()

            train_loss += loss.item()

        train_loss /= len(train_loader)

        # Validation
        model.eval()
        val_loss = 0.0

        with torch.no_grad():
            for batch in tqdm(val_loader, desc=f"Epoch {epoch+1} [Val]"):
                batch = batch.to(device)
                pred = model(batch)
                loss = cosine_similarity_loss(pred, batch.y)
                val_loss += loss.item()

        val_loss /= len(val_loader)

        # Scheduler step
        scheduler.step()

        # Logging
        wandb.log({
            'epoch': epoch,
            'train_loss': train_loss,
            'val_loss': val_loss,
            'learning_rate': optimizer.param_groups[0]['lr']
        })

        print(f"Epoch {epoch+1}/{config['training']['num_epochs']}: "
              f"Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}")

        # Save best model
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': val_loss,
            }, "models/qcgn2oei_best.pth")
            print(f"âœ… Best model saved (Val Loss: {val_loss:.4f})")

    print(f"Training complete. Best Val Loss: {best_val_loss:.4f}")

if __name__ == "__main__":
    train_qcgn2oei()
```

### 2.2 è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«

```yaml
# config/training.yml

model:
  node_dim: 128
  edge_dim: 64
  hidden_dim: 256
  num_layers: 10
  num_heads: 8
  output_dim: 1000  # m/z 50-1000 (950 bins + padding)
  dropout: 0.1

training:
  num_epochs: 300
  batch_size: 32  # RTX 5070 Ti optimal for GNN
  learning_rate: 0.001
  weight_decay: 1e-5
  early_stopping_patience: 50

data:
  bde_cache: "data/processed/bde_cache.h5"
  train_data: "data/processed/nist17_train.pt"
  val_data: "data/processed/nist17_val.pt"
  test_data: "data/processed/nist17_test.pt"
```

### 2.3 å­¦ç¿’æ™‚é–“è¦‹ç©ã‚‚ã‚Š

**RTX 5070 Tiä»•æ§˜**:
- CUDA cores: 8,960
- Tensor cores: 280 (Gen 5)
- Memory: 16GB GDDR7
- Memory bandwidth: 672 GB/s

**1ã‚¨ãƒãƒƒã‚¯ã®æ™‚é–“**:
```
240,000 samples Ã· 32 batch_size = 7,500 iterations
7,500 iterations Ã— 0.8 sec/iter = 6,000 sec = 1.67 hours
```

**åˆè¨ˆå­¦ç¿’æ™‚é–“**:
```
300 epochs Ã— 1.67 hours = 500 hours â†’ early stoppingã§ç´„48æ™‚é–“ï¼ˆ30ã‚¨ãƒãƒƒã‚¯ç¨‹åº¦ã§åæŸæƒ³å®šï¼‰
```

---

## Phase 3: è©•ä¾¡

### 3.1 è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹

```python
# scripts/evaluate.py
"""
Evaluate QC-GN2oEI model
"""

import torch
import numpy as np
from torch_geometric.loader import DataLoader
from src.models.qcgn2oei import QCGN2oEI
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns

def cosine_similarity_metric(pred, target):
    """Calculate cosine similarity"""
    pred_norm = pred / (np.linalg.norm(pred, axis=1, keepdims=True) + 1e-8)
    target_norm = target / (np.linalg.norm(target, axis=1, keepdims=True) + 1e-8)
    return (pred_norm * target_norm).sum(axis=1).mean()

def top_k_recall(pred, target, k=10):
    """
    Top-K Recall: How many of the top-K true peaks are in top-K predictions
    """
    recalls = []
    for p, t in zip(pred, target):
        true_top_k = set(np.argsort(t)[-k:])
        pred_top_k = set(np.argsort(p)[-k:])
        recall = len(true_top_k & pred_top_k) / k
        recalls.append(recall)
    return np.mean(recalls)

def evaluate_model(
    model_path: str = "models/qcgn2oei_best.pth",
    test_data_path: str = "data/processed/nist17_test.pt"
):
    """Comprehensive model evaluation"""

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # Load model
    checkpoint = torch.load(model_path)
    model = QCGN2oEI(...)  # Same config as training
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()

    # Load test data
    test_data = torch.load(test_data_path)
    test_loader = DataLoader(test_data, batch_size=32, shuffle=False)

    # Inference
    all_predictions = []
    all_targets = []

    with torch.no_grad():
        for batch in test_loader:
            batch = batch.to(device)
            pred = model(batch)
            all_predictions.append(pred.cpu().numpy())
            all_targets.append(batch.y.cpu().numpy())

    predictions = np.concatenate(all_predictions, axis=0)
    targets = np.concatenate(all_targets, axis=0)

    # Metrics
    cosine_sim = cosine_similarity_metric(predictions, targets)
    top10_recall = top_k_recall(predictions, targets, k=10)
    top20_recall = top_k_recall(predictions, targets, k=20)

    mse = mean_squared_error(targets.flatten(), predictions.flatten())
    rmse = np.sqrt(mse)

    print("=" * 60)
    print("QC-GN2oEI Evaluation Results")
    print("=" * 60)
    print(f"Cosine Similarity: {cosine_sim:.4f}")
    print(f"Top-10 Recall:     {top10_recall:.4f}")
    print(f"Top-20 Recall:     {top20_recall:.4f}")
    print(f"MSE:               {mse:.6f}")
    print(f"RMSE:              {rmse:.6f}")
    print("=" * 60)

    # Visualization
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))

    # Example spectrum comparison
    idx = 0
    axes[0, 0].stem(targets[idx], linefmt='b-', markerfmt='bo', basefmt=" ", label="True")
    axes[0, 0].stem(predictions[idx], linefmt='r-', markerfmt='ro', basefmt=" ", label="Predicted")
    axes[0, 0].set_xlabel("m/z")
    axes[0, 0].set_ylabel("Intensity")
    axes[0, 0].set_title("Example Spectrum")
    axes[0, 0].legend()

    # Cosine similarity distribution
    cosine_sims = [cosine_similarity_metric(predictions[i:i+1], targets[i:i+1])
                   for i in range(len(predictions))]
    axes[0, 1].hist(cosine_sims, bins=50, alpha=0.7, color='green')
    axes[0, 1].axvline(cosine_sim, color='r', linestyle='--', label=f'Mean: {cosine_sim:.4f}')
    axes[0, 1].set_xlabel("Cosine Similarity")
    axes[0, 1].set_ylabel("Count")
    axes[0, 1].set_title("Cosine Similarity Distribution")
    axes[0, 1].legend()

    # Top-10 recall distribution
    top10_recalls = [top_k_recall(predictions[i:i+1], targets[i:i+1], k=10)
                     for i in range(len(predictions))]
    axes[1, 0].hist(top10_recalls, bins=20, alpha=0.7, color='orange')
    axes[1, 0].axvline(top10_recall, color='r', linestyle='--', label=f'Mean: {top10_recall:.4f}')
    axes[1, 0].set_xlabel("Top-10 Recall")
    axes[1, 0].set_ylabel("Count")
    axes[1, 0].set_title("Top-10 Recall Distribution")
    axes[1, 0].legend()

    # Error vs intensity
    errors = np.abs(predictions - targets).mean(axis=1)
    intensities = targets.max(axis=1)
    axes[1, 1].scatter(intensities, errors, alpha=0.3, s=10)
    axes[1, 1].set_xlabel("Max Intensity")
    axes[1, 1].set_ylabel("Mean Absolute Error")
    axes[1, 1].set_title("Error vs Intensity")

    plt.tight_layout()
    plt.savefig("results/evaluation.png", dpi=300)
    print("âœ… Evaluation plots saved to results/evaluation.png")

if __name__ == "__main__":
    evaluate_model()
```

### 3.2 ç›®æ¨™ç²¾åº¦

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | ç›®æ¨™å€¤ | å‚™è€ƒ |
|----------|--------|------|
| **Cosine Similarity** | > 0.85 | QC-GN2oMS2è«–æ–‡ã§0.88é”æˆ |
| **Top-10 Recall** | > 0.75 | ä¸»è¦ãƒ”ãƒ¼ã‚¯10å€‹ã®å†ç¾ç‡ |
| **Top-20 Recall** | > 0.80 | ä¸»è¦ãƒ”ãƒ¼ã‚¯20å€‹ã®å†ç¾ç‡ |
| **RMSE** | < 0.05 | æ­£è¦åŒ–å¼·åº¦ã§ã®äºŒä¹—å¹³å‡å¹³æ–¹æ ¹èª¤å·® |

---

## è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°

### config.ymlï¼ˆãƒ¡ã‚¤ãƒ³è¨­å®šï¼‰

```yaml
# config.yml - Main Configuration

project:
  name: "QC-GN2oEI"
  version: "2.1"
  description: "Physics-informed GNN for EI-MS prediction with BonDNet BDE-db2"

# BDE Configuration
bde:
  backend: "bondnet"  # Fixed (only option)

  bondnet:
    model_type: "bde-db2"  # Default model (retrained on BDE-db2)
    model_path: "models/bondnet_bde_db2_best.pth"
    dataset_path: "data/external/bde-db2"
    device: "cuda"
    batch_size: 256

    # Fallback for unsupported elements/structures
    fallback:
      aromatic_ring_bond: 120.0  # kcal/mol
      aliphatic_ring_bond: 85.0  # kcal/mol
      default_single_bond: 85.0
      default_double_bond: 146.0
      default_triple_bond: 200.0

# Data paths
data:
  nist17_path: "data/external/nist17/mainlib"
  bde_cache: "data/processed/bde_cache.h5"
  train_data: "data/processed/nist17_train.pt"
  val_data: "data/processed/nist17_val.pt"
  test_data: "data/processed/nist17_test.pt"

# Model architecture
model:
  type: "QCGN2oEI"

  # Node/Edge dimensions
  node_dim: 128
  edge_dim: 64

  # GNN layers
  hidden_dim: 256
  num_layers: 10
  num_heads: 8

  # Output
  output_dim: 1000  # m/z 50-1000 (950 bins + padding)

  # Regularization
  dropout: 0.1

  # Advanced features
  use_residual: true
  use_edge_features: true
  global_pooling: "mean"

# Training
training:
  num_epochs: 300
  batch_size: 32
  learning_rate: 0.001
  weight_decay: 1e-5

  # Optimizer
  optimizer: "RAdam"  # Same as QC-GN2oMS2

  # Scheduler
  scheduler: "CosineAnnealingLR"
  scheduler_params:
    T_max: 300
    eta_min: 1e-6

  # Loss function
  loss: "cosine_similarity"

  # Early stopping
  early_stopping_patience: 50

  # Checkpointing
  save_every: 10  # Save checkpoint every 10 epochs
  checkpoint_dir: "checkpoints"

# Evaluation
evaluation:
  metrics:
    - "cosine_similarity"
    - "top_k_recall"
    - "mse"
    - "rmse"

  top_k_values: [5, 10, 20, 50]

  # Visualization
  plot_examples: 10
  plot_dir: "results/plots"

# Hardware
hardware:
  device: "cuda"
  gpu_id: 0
  num_workers: 4
  pin_memory: true

  # Mixed precision training
  use_amp: true
  amp_dtype: "float16"

  # Memory optimization
  gradient_accumulation_steps: 1
  empty_cache_every: 100  # Empty CUDA cache every 100 batches

# Logging
logging:
  use_wandb: true
  wandb_project: "qcgn2oei"
  wandb_entity: null  # Set your wandb username

  log_every: 10  # Log every 10 batches
  save_predictions: true

# Reproducibility
seed: 42
deterministic: true
```

---

## é–‹ç™ºç’°å¢ƒæ§‹ç¯‰

### Dockerfileï¼ˆæ›´æ–°ç‰ˆ: Pure PyTorchï¼‰

```dockerfile
# .devcontainer/Dockerfile
# PyTorch-only environment for RTX 5070 Ti (sm_120)

FROM nvidia/cuda:12.8.0-cudnn-devel-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    CUDA_HOME=/usr/local/cuda-12.8 \
    PATH=/usr/local/cuda-12.8/bin:$PATH \
    LD_LIBRARY_PATH=/usr/local/cuda-12.8/lib64:$LD_LIBRARY_PATH \
    LANG=en_US.UTF-8 \
    LC_ALL=en_US.UTF-8 \
    TORCH_CUDA_ARCH_LIST="9.0;12.0" \
    CUDA_LAUNCH_BLOCKING=0 \
    PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

WORKDIR /workspace

# System packages
RUN apt-get update && \
    apt-get install -y --no-install-recommends software-properties-common && \
    add-apt-repository -y ppa:deadsnakes/ppa && \
    apt-get update && \
    apt-get install -y --no-install-recommends \
    git wget curl vim build-essential cmake gcc g++ \
    ca-certificates gnupg lsb-release \
    python3.11 python3.11-dev python3.11-venv python3-pip \
    libssl-dev libffi-dev libxml2-dev libxslt1-dev zlib1g-dev \
    libopenblas-dev liblapack-dev libhdf5-dev \
    && rm -rf /var/lib/apt/lists/*

# Node.js for Claude CLI
RUN curl -fsSL https://deb.nodesource.com/setup_20.x | bash - && \
    apt-get install -y nodejs && \
    rm -rf /var/lib/apt/lists/*

RUN npm install -g @anthropic-ai/claude-code

# Python 3.11 default
RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1 && \
    update-alternatives --install /usr/bin/python python /usr/bin/python3.11 1

# Virtual environment
RUN python3.11 -m venv /opt/venv

RUN ln -sf /opt/venv/bin/python /usr/bin/python && \
    ln -sf /opt/venv/bin/python /usr/bin/python3 && \
    ln -sf /opt/venv/bin/pip /usr/bin/pip && \
    ln -sf /opt/venv/bin/pip /usr/bin/pip3

ENV PATH="/opt/venv/bin:$PATH"

# ===================================================
# PyTorch Nightly (cu128) - RTX 5070 Ti support
# ===================================================
RUN pip install --no-cache-dir nvidia-nvshmem-cu12==3.4.5

RUN pip install --no-cache-dir --pre \
    torch torchvision torchaudio \
    --index-url https://download.pytorch.org/whl/nightly/cu128

# ===================================================
# Python packages (PyTorch-only stack)
# ===================================================
RUN pip install --no-cache-dir six hatchling wheel ninja

# Scientific computing
RUN pip install --no-cache-dir \
    numpy==1.26.4 \
    scipy==1.13.0 \
    pandas==2.2.2 \
    matplotlib==3.8.4 \
    seaborn==0.13.2 \
    plotly==5.20.0 \
    h5py==3.11.0 \
    pyyaml \
    tqdm \
    scikit-learn

# Chemistry libraries
RUN pip install --no-cache-dir \
    rdkit \
    mordred \
    mol2vec

# Jupyter
RUN pip install --no-cache-dir \
    jupyter \
    jupyterlab \
    ipython

# ===================================================
# PyTorch Geometric (sm_120 support)
# ===================================================
RUN pip install --no-cache-dir torch-geometric

# Build PyG extensions from source for sm_120
RUN export FORCE_CUDA=1 && \
    export TORCH_CUDA_ARCH_LIST="9.0;12.0" && \
    export CUDA_HOME=/usr/local/cuda-12.8 && \
    echo "Building PyG extensions from source..." && \
    pip install --no-cache-dir --no-build-isolation torch-scatter && \
    pip install --no-cache-dir --no-build-isolation torch-sparse torch-cluster torch-spline-conv

# ===================================================
# BonDNet and DGL (PyTorch-only)
# ===================================================
# Install DGL with CUDA 12.8 support
RUN pip install --no-cache-dir dgl -f https://data.dgl.ai/wheels/cu128/repo.html

# Install BonDNet from GitHub
RUN pip install --no-cache-dir git+https://github.com/txie-93/bondnet.git

# OGB for benchmarking
RUN pip install --no-cache-dir ogb>=1.3.6

# ML tools
RUN pip install --no-cache-dir \
    tensorboard \
    wandb \
    torch-ema

# Development tools
RUN pip install --no-cache-dir \
    pytest \
    black \
    flake8 \
    mypy

# Non-root user
RUN useradd -m -s /bin/bash devuser && \
    chown -R devuser:devuser /workspace && \
    chown -R devuser:devuser /opt/venv

# Auto-activate venv
RUN echo "source /opt/venv/bin/activate" >> /home/devuser/.bashrc && \
    echo "source /opt/venv/bin/activate" >> /root/.bashrc

ENV PYTHONPATH="/workspace:$PYTHONPATH"

# GPU verification script
RUN cat <<'SCRIPT' > /usr/local/bin/verify-gpu.py
#!/usr/bin/env python3
import torch
import sys

print("=" * 60)
print("RTX 50ã‚·ãƒªãƒ¼ã‚º GPUæ¤œè¨¼")
print("=" * 60)

cuda_available = torch.cuda.is_available()
print(f"CUDAåˆ©ç”¨å¯èƒ½: {cuda_available}")

if cuda_available:
    device_count = torch.cuda.device_count()
    print(f"GPUãƒ‡ãƒã‚¤ã‚¹æ•°: {device_count}")

    for i in range(device_count):
        props = torch.cuda.get_device_properties(i)
        print(f"\nGPU {i}: {torch.cuda.get_device_name(i)}")
        print(f"  Compute Capability: {props.major}.{props.minor}")
        print(f"  ãƒ¡ãƒ¢ãƒª: {props.total_memory / 1e9:.1f} GB")
        print(f"  SMæ•°: {props.multi_processor_count}")

        if props.major == 12 and props.minor == 0:
            print(f"  âœ… sm_120 (Blackwell) æ¤œå‡º!")

    print(f"\nPyTorch Version: {torch.__version__}")
    print(f"CUDA Version: {torch.version.cuda}")

    # GPU test
    try:
        test_tensor = torch.randn(1000, 1000).cuda()
        result = torch.mm(test_tensor, test_tensor)
        print("\nâœ… GPUæ¼”ç®—ãƒ†ã‚¹ãƒˆæˆåŠŸ!")
    except Exception as e:
        print(f"\nâŒ GPUæ¼”ç®—ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        sys.exit(1)

    # PyG test
    try:
        import torch_scatter
        print(f"\nâœ… torch_scatter ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿")
        src = torch.randn(10, 5).cuda()
        index = torch.tensor([0, 1, 0, 1, 2, 0, 1, 2, 0, 1]).cuda()
        out = torch_scatter.scatter(src, index, dim=0, reduce="sum")
        print(f"   torch_scatter CUDAæ¼”ç®—ãƒ†ã‚¹ãƒˆæˆåŠŸ!")
    except Exception as e:
        print(f"\nâŒ torch_scatter ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)

    # BonDNet test
    try:
        import dgl
        import bondnet
        print(f"\nâœ… DGL version: {dgl.__version__}")
        print(f"âœ… BonDNet ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿")
    except Exception as e:
        print(f"\nâŒ BonDNet ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)
else:
    print("âŒ CUDAãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
    sys.exit(1)

print("=" * 60)
SCRIPT

RUN chmod +x /usr/local/bin/verify-gpu.py

USER devuser

CMD ["/bin/bash"]
```

### devcontainer.json

```json
{
  "name": "NExtIMS QC-GN2oEI (PyTorch + RTX 5070 Ti)",
  "dockerFile": "Dockerfile",
  "runArgs": [
    "--gpus", "all",
    "--ipc=host",
    "--ulimit", "memlock=-1",
    "--ulimit", "stack=67108864"
  ],
  "customizations": {
    "vscode": {
      "extensions": [
        "ms-python.python",
        "ms-python.vscode-pylance",
        "ms-toolsai.jupyter",
        "GitHub.copilot"
      ],
      "settings": {
        "python.defaultInterpreterPath": "/opt/venv/bin/python",
        "python.linting.enabled": true,
        "python.linting.flake8Enabled": true,
        "python.formatting.provider": "black"
      }
    }
  },
  "postCreateCommand": "python /usr/local/bin/verify-gpu.py"
}
```

---

## ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³

### å…¨ä½“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

| ãƒ•ã‚§ãƒ¼ã‚º | ã‚¿ã‚¹ã‚¯ | æ¨å®šæ™‚é–“ | ç´¯ç©æ™‚é–“ |
|---------|--------|---------|---------|
| **Phase 0** | BDE-db2ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ | 30åˆ† | 30åˆ† |
| **Phase 0** | ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç† | 3æ™‚é–“ | 3.5æ™‚é–“ |
| **Phase 0** | BonDNetå†å­¦ç¿’ | 48-72æ™‚é–“ | 51.5-75.5æ™‚é–“ |
| **Phase 0** | ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ | 1æ™‚é–“ | 52.5-76.5æ™‚é–“ |
| **Phase 1** | NISTèª­ã¿è¾¼ã¿ | 30åˆ† | 53-77æ™‚é–“ |
| **Phase 1** | BDEè¨ˆç®—ï¼ˆBonDNetï¼‰ | 75åˆ† | 54.25-78.25æ™‚é–“ |
| **Phase 1** | PyG Graphç”Ÿæˆ | 60åˆ† | 55.25-79.25æ™‚é–“ |
| **Phase 2** | GNNå­¦ç¿’ | 48æ™‚é–“ | 103.25-127.25æ™‚é–“ |
| **Phase 3** | è©•ä¾¡ | 2æ™‚é–“ | 105.25-129.25æ™‚é–“ |
| **åˆè¨ˆ** | - | **105-130æ™‚é–“** | **4.4-5.4æ—¥** |

### ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒ‘ã‚¹

```
Phase 0 (BonDNetå†å­¦ç¿’) â†’ Phase 1 (BDEè¨ˆç®—) â†’ Phase 2 (GNNå­¦ç¿’) â†’ Phase 3 (è©•ä¾¡)
```

**ä¸¦åˆ—åŒ–å¯èƒ½ãªä½œæ¥­**:
- Phase 0å®Ÿè¡Œä¸­: ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼å®Ÿè£…ã€GNNãƒ¢ãƒ‡ãƒ«å®Ÿè£…
- Phase 1å®Ÿè¡Œä¸­: å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè£…ã€è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè£…

---

## å‚è€ƒæ–‡çŒ®

### è«–æ–‡

1. **QC-GN2oMS2 (Original)**:
   - Zhang et al. (2024). "Quantum Chemistry-Informed Graph Neural Network for Mass Spectrum Prediction"
   - *Journal of Chemical Information and Modeling*
   - DOI: 10.1021/acs.jcim.4c00497
   - GitHub: https://github.com/PNNL-m-q/qcgnoms

2. **BonDNet**:
   - Xie & Grossman (2022). "Crystal Graph Convolutional Neural Networks for Accurate and Interpretable Prediction of Material Properties"
   - *Physical Review Letters*
   - GitHub: https://github.com/txie-93/bondnet

3. **BDE-db2**:
   - St. John et al. (2020). "A comprehensive database of bond dissociation enthalpies in organic molecules"
   - *Nature Scientific Data*
   - GitHub: https://github.com/patongroup/BDE-db2

4. **GATv2**:
   - Brody et al. (2021). "How Attentive are Graph Attention Networks?"
   - *ICLR 2022*

### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

- **NIST 17**: NIST Mass Spectral Library (2017)
- **BDE-db2**: 531,244 bond dissociation energies (Paton Group)

### ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢

- **PyTorch**: 2.10.0+ (nightly, CUDA 12.8)
- **PyTorch Geometric**: 2.6.1
- **DGL**: 2.1.0+
- **BonDNet**: Latest from GitHub
- **RDKit**: 2024.03.1

---

## ã¾ã¨ã‚

### v4.0ã®ä¸»è¦ãªæ”¹å–„ç‚¹

1. **Pure PyTorchç’°å¢ƒ**: TensorFlowä¾å­˜ã‚’å®Œå…¨å‰Šé™¤
2. **BonDNet BDE-db2ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåŒ–**: æœ€å¤§ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã¨ç²¾åº¦
3. **ã‚·ãƒ³ãƒ—ãƒ«ãªæ§‹æˆ**: ãƒ—ãƒ©ã‚¬ãƒ–ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å‰Šé™¤ã€ä¿å®ˆæ€§å‘ä¸Š
4. **å®Ÿè£…å¯èƒ½æ€§**: xTBã®é–“æ¥BDEè¨ˆç®—ã®è¤‡é›‘ã•ã‚’æ’é™¤

### æœŸå¾…ã•ã‚Œã‚‹æˆæœ

- **ç²¾åº¦**: Cosine Similarity > 0.85
- **é€Ÿåº¦**: æ¨è«–15ms/åˆ†å­ï¼ˆå®Ÿç”¨ãƒ¬ãƒ™ãƒ«ï¼‰
- **ã‚«ãƒãƒ¬ãƒƒã‚¸**: NIST 17ã®95%ä»¥ä¸Šã‚’ã‚µãƒãƒ¼ãƒˆ
- **è§£é‡ˆæ€§**: BDEã‚¨ãƒƒã‚¸ç‰¹å¾´ã«ã‚ˆã‚‹ç‰©ç†åŒ–å­¦çš„è§£é‡ˆå¯èƒ½æ€§

---

**Document Version**: 4.0
**Last Updated**: 2025-12-02
**Status**: Ready for Implementation
