# QC-GN2oMS2-EI „Ç∑„Çπ„ÉÜ„É†Ë©≥Á¥∞ÊäÄË°ì‰ªïÊßòÊõ∏ v4.2
## PyTorchÁµ±‰∏ÄÁí∞Â¢É„ÉªÊúÄÂ∞èÊßãÊàê„Ç¢„Éó„É≠„Éº„ÉÅÔºàÂèçÂæ©ÊîπÂñÑÊà¶Áï•Ôºâ

**‰ΩúÊàêÊó•**: 2025-12-02
**ÂØæË±°„Ç∑„Çπ„ÉÜ„É†**: NExtIMS (NIST EI-MS Prediction System)
**Âü∫Áõ§„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£**: QC-GN2oMS2 (PNNL)
**„Éè„Éº„Éâ„Ç¶„Çß„Ç¢**: NVIDIA GeForce RTX 5070 Ti (Blackwell sm_120)
**Ë®≠Ë®àÊñπÈáù**: **Start Simple, Iterate Based on Evidence**

---

## üìã ÁõÆÊ¨°

1. [‰∏ªË¶ÅÂ§âÊõ¥ÁÇπÔºàv4.1 ‚Üí v4.2Ôºâ](#‰∏ªË¶ÅÂ§âÊõ¥ÁÇπv41--v42)
2. [Ë®≠Ë®àÂì≤Â≠¶ÔºöÊúÄÂ∞èÊßãÊàê„Ç¢„Éó„É≠„Éº„ÉÅ](#Ë®≠Ë®àÂì≤Â≠¶ÊúÄÂ∞èÊßãÊàê„Ç¢„Éó„É≠„Éº„ÉÅ)
3. [„Ç∑„Çπ„ÉÜ„É†Ê¶ÇË¶Å](#„Ç∑„Çπ„ÉÜ„É†Ê¶ÇË¶Å)
4. [„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£Ë®≠Ë®à](#„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£Ë®≠Ë®à)
5. [Phase 0: BDE-db2Áí∞Â¢ÉÊßãÁØâ](#phase-0-bde-db2Áí∞Â¢ÉÊßãÁØâ)
6. [Phase 1: „Éá„Éº„ÇøÊ∫ñÂÇô](#phase-1-„Éá„Éº„ÇøÊ∫ñÂÇô)
7. [Phase 2: GNNÂ≠¶Áøí](#phase-2-gnnÂ≠¶Áøí)
8. [Phase 3: Ë©ï‰æ°„Å®ÂèçÂæ©ÊîπÂñÑÂà§Êñ≠](#phase-3-Ë©ï‰æ°„Å®ÂèçÂæ©ÊîπÂñÑÂà§Êñ≠)
9. [Phase 4: ÁâπÂæ¥ÈáèÊã°ÂºµÔºàÊù°‰ª∂‰ªò„ÅçÔºâ](#phase-4-ÁâπÂæ¥ÈáèÊã°ÂºµÊù°‰ª∂‰ªò„Åç)
10. [Ë®≠ÂÆö„Éï„Ç°„Ç§„É´Ë©≥Á¥∞](#Ë®≠ÂÆö„Éï„Ç°„Ç§„É´Ë©≥Á¥∞)
11. [ÈñãÁô∫Áí∞Â¢ÉÊßãÁØâ](#ÈñãÁô∫Áí∞Â¢ÉÊßãÁØâ)
12. [„Çø„Ç§„É†„É©„Ç§„É≥](#„Çø„Ç§„É†„É©„Ç§„É≥)
13. [ÂèÇËÄÉÊñáÁåÆ](#ÂèÇËÄÉÊñáÁåÆ)

---

## ‰∏ªË¶ÅÂ§âÊõ¥ÁÇπÔºàv4.1 ‚Üí v4.2Ôºâ

### ‚úÖ v4.2„Åß„ÅÆÂ§ßÂπÖÁ∞°Á¥†Âåñ

| È†ÖÁõÆ | v4.1 | v4.2 | Â§âÊõ¥ÁêÜÁî± |
|------|------|------|---------|
| **„Éé„Éº„ÉâÁâπÂæ¥Ê¨°ÂÖÉ** | 128 (41+87) | **16 (16+0)** | QC-GN2oMS2ÂÆüË®ºÊ∏à„ÅøË®≠Ë®à„Å´Ê∫ñÊã† |
| **„Ç®„ÉÉ„Ç∏ÁâπÂæ¥Ê¨°ÂÖÉ** | 64 (12+52) | **3 (3+0)** | ÊúÄÂ∞èÈôê„ÅÆÁâπÂæ¥ÈáèÔºàBDE+ÁµêÂêàÊ¨°Êï∞+Áí∞Ôºâ |
| **‰∫àÂÇôÊ¨°ÂÖÉ** | 139 (87+52) | **0** | ÂÆüË®º‰∏ªÁæ©„Ç¢„Éó„É≠„Éº„ÉÅÔºàÂøÖË¶ÅÊÄßË®ºÊòéÂæå„Å´ËøΩÂä†Ôºâ |
| **„É°„É¢„É™‰ΩøÁî®Èáè** | Á¥Ñ1.3GB | **Á¥Ñ0.16GB** | **-88%ÂâäÊ∏õ** |
| **Ë®≠Ë®àÊñπÈáù** | Êã°ÂºµÊÄßÈáçË¶ñ | **„Ç∑„É≥„Éó„É´„ÅïÈáçË¶ñ** | Start simple, iterate |

### üéØ Ë®≠Ë®àÂì≤Â≠¶„ÅÆËª¢Êèõ

**v4.1**: „ÄåÂ∞ÜÊù•„ÅÆÊã°Âºµ„Å´ÂÇô„Åà„Å¶‰∫àÂÇôÊ¨°ÂÖÉ„ÇíÂ§ßÈáè„Å´Á¢∫‰øù„Äç
**v4.2**: „ÄåÊúÄÂ∞èÊßãÊàê„ÅßÂÆüË£Ö ‚Üí ÊÄßËÉΩË©ï‰æ° ‚Üí ÂøÖË¶Å„Å´Âøú„Åò„Å¶ÊÆµÈöéÁöÑ„Å´Êã°Âºµ„Äç

**Ê†πÊã†**:
- QC-GN2oMS2„ÅåMS/MS„Åß16Ê¨°ÂÖÉ„Éé„Éº„ÉâÁâπÂæ¥„ÄÅ2Ê¨°ÂÖÉ„Ç®„ÉÉ„Ç∏ÁâπÂæ¥„Åß**Cosine Similarity 0.88**„ÇíÈÅîÊàê
- ÈÅéÂâ∞Ë®≠Ë®à„ÇíÈÅø„Åë„ÄÅÂÆüË®º„Éá„Éº„Çø„Å´Âü∫„Å•„ÅèÊÑèÊÄùÊ±∫ÂÆö
- È´òÈÄü„Ç§„ÉÜ„É¨„Éº„Ç∑„Éß„É≥ÔºàÂ≠¶ÁøíÈÄüÂ∫¶Âêë‰∏äÔºâ„Å´„Çà„Çã„Ç¢„Ç∏„É£„Ç§„É´ÈñãÁô∫

---

## Ë®≠Ë®àÂì≤Â≠¶ÔºöÊúÄÂ∞èÊßãÊàê„Ç¢„Éó„É≠„Éº„ÉÅ

### Âü∫Êú¨ÂéüÂâá

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Phase 1: ÊúÄÂ∞èÊßãÊàê„ÅßÂÆüË£ÖÔºàv4.2Ôºâ                          ‚îÇ
‚îÇ   - „Éé„Éº„Éâ: 16Ê¨°ÂÖÉÔºàQC-GN2oMS2Ê∫ñÊã†Ôºâ                     ‚îÇ
‚îÇ   - „Ç®„ÉÉ„Ç∏: 3Ê¨°ÂÖÉÔºàBDE + ÁµêÂêàÊ¨°Êï∞ + Áí∞Ôºâ                 ‚îÇ
‚îÇ   - ÁõÆÊ®ô: Cosine Similarity > 0.80                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ Phase 2: ÊÄßËÉΩË©ï‰æ°    ‚îÇ
         ‚îÇ   - Cosine Sim       ‚îÇ
         ‚îÇ   - Top-K Recall     ‚îÇ
         ‚îÇ   - Ê±éÂåñÊÄßËÉΩ         ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Âà§ÂÆö                           ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ ÂçÅÂàÜ       ‚îÇ ‰∏çÂçÅÂàÜ           ‚îÇ
    ‚îÇ (>0.85)    ‚îÇ (<0.85)          ‚îÇ
    ‚Üì            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ÂÆå‰∫ÜÔºÅ  ‚îÇ  ‚îÇ Phase 3: ÁâπÂæ¥ÈáèÂàÜÊûê  ‚îÇ
‚îÇ v4.2Êé°Áî®‚îÇ  ‚îÇ   - AttentionÂàÜÊûê    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ   - Ablation study   ‚îÇ
             ‚îÇ   - ÈáçË¶ÅÁâπÂæ¥„ÅÆÁâπÂÆö   ‚îÇ
             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì
             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
             ‚îÇ Phase 4: ÊÆµÈöéÁöÑÊã°Âºµ  ‚îÇ
             ‚îÇ   - v4.3: ËøΩÂä†ÁâπÂæ¥   ‚îÇ
             ‚îÇ   - ÂÜçË©ï‰æ°           ‚îÇ
             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### QC-GN2oMS2„ÅÆÊïôË®ì

**ÂΩº„Çâ„ÅÆÊàêÂäü‰∫ã‰æã**:
- MS/MS„Åß16Ê¨°ÂÖÉ„Éé„Éº„Éâ„ÄÅ2Ê¨°ÂÖÉ„Ç®„ÉÉ„Ç∏
- Cosine Similarity 0.88ÈÅîÊàê
- Ë´ñÊñá„ÅßÂÆüË®ºÊ∏à„Åø

**Êàë„ÄÖ„ÅÆ‰ªÆË™¨**:
- EI-MS„ÇÇ„Ç∑„É≥„Éó„É´„Å™ÁâπÂæ¥Èáè„ÅßÂçÅÂàÜ„Å™ÂèØËÉΩÊÄß
- Ë§áÈõë„Åï„ÅØÊÆµÈöéÁöÑ„Å´ËøΩÂä†„Åô„Åπ„Åç
- ÊúÄÂàù„Åã„Çâ128Ê¨°ÂÖÉ„ÅØÈÅéÂâ∞Ë®≠Ë®à„ÅÆÂèØËÉΩÊÄßÂ§ß

---

## „Ç∑„Çπ„ÉÜ„É†Ê¶ÇË¶Å

### ÁõÆÁöÑ

NIST 17 EI-MS„Éá„Éº„Çø„Éô„Éº„ÇπÔºàÁ¥Ñ280,000„Çπ„Éö„ÇØ„Éà„É´„ÄÅ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞ÂæåÔºâ„ÇíÁî®„ÅÑ„Å¶„ÄÅ**ÊúÄÂ∞èÈôê„ÅÆÁâπÂæ¥Èáè„ÅßÈ´òÁ≤æÂ∫¶„Å™**Graph Neural Network„Å´„Çà„ÇãEI-MS„Çπ„Éö„ÇØ„Éà„É´‰∫àÊ∏¨„Ç∑„Çπ„ÉÜ„É†„ÇíÊßãÁØâ„Åô„Çã„ÄÇ

### „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£Ê¶ÇË¶ÅÂõ≥

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Phase 0: BDE-db2Áí∞Â¢ÉÊßãÁØâÔºàv4.1„Å®Âêå„ÅòÔºâ                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. BDE-db2„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ (531,244 reactions)                   ‚îÇ
‚îÇ 2. BonDNetÂÜçÂ≠¶Áøí (2-3Êó•, RTX 5070 Ti)                        ‚îÇ
‚îÇ 3. Â≠¶ÁøíÊ∏à„Åø„É¢„Éá„É´Ê§úË®º (MAE < 1.0 kcal/molÁõÆÊ®ô)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Phase 1: „Éá„Éº„ÇøÊ∫ñÂÇôÔºàv4.1„Å®Âêå„ÅòÔºâ                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1.1 NIST 17Ë™≠„ÅøËæº„Åø (300,000 spectra)                       ‚îÇ
‚îÇ 1.2 „Éá„Éº„Çø„Éï„Ç£„É´„Çø„É™„É≥„Ç∞                                     ‚îÇ
‚îÇ     - „Çµ„Éù„Éº„ÉàÂÖÉÁ¥†„ÉÅ„Çß„ÉÉ„ÇØ (C,H,O,N,F,S,P,Cl,Br,I)          ‚îÇ
‚îÇ     - ÂàÜÂ≠êÈáè„Éï„Ç£„É´„Çø (MW <= 1000 Da)                         ‚îÇ
‚îÇ     ‚Üí 280,000 spectra (93.3% retention)                     ‚îÇ
‚îÇ 1.3 BonDNet BDEË®àÁÆó (70 min)                                ‚îÇ
‚îÇ 1.4 PyG GraphÁîüÊàêÔºà16Ê¨°ÂÖÉ„Éé„Éº„Éâ„ÄÅ3Ê¨°ÂÖÉ„Ç®„ÉÉ„Ç∏Ôºâ              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Phase 2: GNNÂ≠¶ÁøíÔºàÊúÄÂ∞èÊßãÊàêÔºâ                                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 10-layer GATv2Conv + Residual Connections                   ‚îÇ
‚îÇ „Éé„Éº„Éâ: 16Ê¨°ÂÖÉ„ÄÅ„Ç®„ÉÉ„Ç∏: 3Ê¨°ÂÖÉ                               ‚îÇ
‚îÇ RTX 5070 Ti (16GB GDDR7) √ó Á¥Ñ40ÊôÇÈñìÔºàÈ´òÈÄüÂåñÔºâ                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Phase 3: Ë©ï‰æ°„Å®ÂèçÂæ©ÊîπÂñÑÂà§Êñ≠ÔºàNEW!Ôºâ                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ - Cosine SimilarityË©ï‰æ°                                     ‚îÇ
‚îÇ - Top-K RecallË©ï‰æ°                                          ‚îÇ
‚îÇ - Ê±éÂåñÊÄßËÉΩË©ï‰æ°ÔºàÊú™Áü•ÂåñÂêàÁâ©„ÉÜ„Çπ„ÉàÔºâ                          ‚îÇ
‚îÇ - Attention weightsÂàÜÊûê                                     ‚îÇ
‚îÇ ‚Üí Âà§ÂÆö: ÂçÅÂàÜ or ÁâπÂæ¥ÈáèËøΩÂä†ÂøÖË¶Å                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£Ë®≠Ë®à

### BDEË®àÁÆó„Éê„ÉÉ„ÇØ„Ç®„É≥„Éâ: BonDNet (BDE-db2ÂÜçÂ≠¶ÁøíÁâà)

Ôºàv4.1„Å®Âêå„Åò - Â§âÊõ¥„Å™„ÅóÔºâ

---

### GNN„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£: 10-layer GATv2ConvÔºàÊúÄÂ∞èÊßãÊàêÁâàÔºâ

#### „É¢„Éá„É´ÊßãÊàê

```python
import torch
import torch.nn as nn
from torch_geometric.nn import GATv2Conv, global_mean_pool

class QCGN2oEI_Minimal(nn.Module):
    """
    QC-GN2oMS2 Architecture for EI-MS Prediction (Minimal Configuration)

    Key design:
    - Minimal feature dimensions (16 node, 3 edge)
    - Inspired by QC-GN2oMS2's proven approach
    - Iterate based on performance evaluation
    """

    def __init__(
        self,
        node_dim: int = 16,        # Minimal node feature dimension
        edge_dim: int = 3,         # Minimal edge feature dimension
        hidden_dim: int = 256,     # Hidden layer dimension
        num_layers: int = 10,      # GATv2Conv layers
        num_heads: int = 8,        # Attention heads
        output_dim: int = 1000,    # Output spectrum bins (m/z 50-1000)
        dropout: float = 0.1
    ):
        super().__init__()

        # Node embedding (16 ‚Üí 256)
        self.node_encoder = nn.Sequential(
            nn.Linear(node_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout)
        )

        # Edge embedding (3 ‚Üí 256)
        self.edge_encoder = nn.Sequential(
            nn.Linear(edge_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout)
        )

        # 10-layer GATv2Conv with residual connections
        self.gat_layers = nn.ModuleList()
        self.residual_layers = nn.ModuleList()

        for i in range(num_layers):
            # GATv2Conv layer
            self.gat_layers.append(
                GATv2Conv(
                    in_channels=hidden_dim,
                    out_channels=hidden_dim // num_heads,
                    heads=num_heads,
                    edge_dim=hidden_dim,  # Edge features
                    dropout=dropout,
                    concat=True,          # Concatenate heads
                    residual=True         # PyG 2.6.1+ feature
                )
            )

            # Residual connection projection
            self.residual_layers.append(
                nn.Linear(hidden_dim, hidden_dim)
            )

        # Global pooling + prediction head
        self.prediction_head = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim * 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, output_dim),
            nn.Softmax(dim=-1)  # Normalize to intensity distribution
        )

    def forward(self, data):
        """
        Args:
            data: PyG Data object
                - x: Node features [num_nodes, 16]
                - edge_index: Graph connectivity [2, num_edges]
                - edge_attr: Edge features [num_edges, 3]
                - batch: Batch assignment [num_nodes]

        Returns:
            spectrum: Predicted intensity [batch_size, 1000]
        """
        # Encode nodes and edges
        x = self.node_encoder(data.x)
        edge_attr = self.edge_encoder(data.edge_attr)

        # 10-layer GATv2Conv with residual connections
        for gat, residual in zip(self.gat_layers, self.residual_layers):
            x_res = residual(x)  # Residual projection
            x = gat(x, data.edge_index, edge_attr)
            x = x + x_res  # Residual addition
            x = torch.relu(x)

        # Global mean pooling
        x = global_mean_pool(x, data.batch)

        # Predict spectrum
        spectrum = self.prediction_head(x)

        return spectrum
```

#### „Éé„Éº„ÉâÁâπÂæ¥ÈáèÔºà16Ê¨°ÂÖÉÔºâ- QC-GN2oMS2Ê∫ñÊã†

**Ë®≠Ë®àÊñπÈáù**: QC-GN2oMS2„ÅåÂÆüË®º„Åó„ÅüÊúÄÂ∞èÈôê„ÅÆÁâπÂæ¥Èáè„Çª„ÉÉ„Éà

| „Ç´„ÉÜ„Ç¥„É™ | Ê¨°ÂÖÉ | ÂÜÖÂÆπ | ÁêÜÁî± |
|---------|------|------|------|
| **ÂéüÂ≠êÁ®Æ** | 10 | C, H, O, N, F, S, P, Cl, Br, I (one-hot) | ÂÖÉÁ¥†Á®Æ„ÅØÊúÄÈáçË¶ÅÁâπÂæ¥ |
| **Ëä≥È¶ôÊóèÊÄß** | 1 | Binary (aromatic/aliphatic) | „Éï„É©„Ç∞„É°„É≥„ÉÜ„Éº„Ç∑„Éß„É≥ÂÆâÂÆöÊÄß |
| **Áí∞ÊßãÈÄ†** | 1 | Binary (in ring/not in ring) | ÊßãÈÄ†ÁöÑÂÆâÂÆöÊÄß |
| **„Éè„Ç§„Éñ„É™„ÉÄ„Ç§„Çº„Éº„Ç∑„Éß„É≥** | 3 | SP/SP2/SP3 (one-hot) | ÁµêÂêà„ÅÆÊÄßË≥™ |
| **ÈÉ®ÂàÜÈõªËç∑** | 1 | Gasteiger charge (continuous) | ÈõªÂ≠êÂàÜÂ∏É |
| **ÂêàË®à** | **16** | - | **‰∫àÂÇô„Å™„Åó** |

**ÂâäÈô§„Åï„Çå„ÅüÁâπÂæ¥Ôºàv4.1„Å´„ÅÇ„Å£„Åü„ÇÇ„ÅÆÔºâ**:
- ÂΩ¢ÂºèÈõªËç∑Ôºà3Ê¨°ÂÖÉÔºâ ‚Üí ÈÉ®ÂàÜÈõªËç∑„Åß‰ª£ÊõøÂèØËÉΩ
- Ê∞¥Á¥†ÁµêÂêàÊï∞Ôºà5Ê¨°ÂÖÉÔºâ ‚Üí ÂéüÂ≠êÁ®Æ+„Éè„Ç§„Éñ„É™„ÉÄ„Ç§„Çº„Éº„Ç∑„Éß„É≥„Åã„ÇâÊé®Ê∏¨ÂèØËÉΩ
- Ê¨°Êï∞Ôºà6Ê¨°ÂÖÉÔºâ ‚Üí „Ç∞„É©„ÉïÊßãÈÄ†„Åã„ÇâÂ≠¶ÁøíÂèØËÉΩ
- „É©„Ç∏„Ç´„É´ÈõªÂ≠êÔºà3Ê¨°ÂÖÉÔºâ ‚Üí EI-MS„Åß„ÅØ„ÅÇ„Åæ„ÇäÈáçË¶Å„Åß„Å™„ÅÑÂèØËÉΩÊÄß
- „Ç≠„É©„É™„ÉÜ„Ç£Ôºà3Ê¨°ÂÖÉÔºâ ‚Üí Á´ã‰ΩìÂåñÂ≠¶„ÅØ‰∫åÊ¨°ÁöÑ
- ÂéüÂ≠êÈáè„ÉªvdWÂçäÂæÑ„ÉªÈõªÊ∞óÈô∞ÊÄßÂ∫¶Ôºà3Ê¨°ÂÖÉÔºâ ‚Üí ÂéüÂ≠êÁ®Æ„Å®Áõ∏Èñ¢

**ÂÆüË£Ö‰æã**:
```python
from rdkit import Chem
from rdkit.Chem import AllChem
import numpy as np

SUPPORTED_ELEMENTS = ['C', 'H', 'O', 'N', 'F', 'S', 'P', 'Cl', 'Br', 'I']

def get_atom_features_minimal(atom: Chem.Atom) -> np.ndarray:
    """
    Extract 16-dimensional minimal atom features

    Inspired by QC-GN2oMS2's proven approach
    """

    # 1. Atom type (10-dim one-hot)
    atom_symbol = atom.GetSymbol()
    if atom_symbol not in SUPPORTED_ELEMENTS:
        raise ValueError(f"Unsupported element: {atom_symbol}")
    atom_type = one_hot(atom_symbol, SUPPORTED_ELEMENTS)  # 10 dims

    # 2. Aromatic (1-dim binary)
    aromatic = [int(atom.GetIsAromatic())]  # 1 dim

    # 3. In ring (1-dim binary)
    in_ring = [int(atom.IsInRing())]  # 1 dim

    # 4. Hybridization (3-dim one-hot: SP/SP2/SP3)
    hyb = atom.GetHybridization()
    if hyb == Chem.HybridizationType.SP:
        hybrid = [1, 0, 0]
    elif hyb == Chem.HybridizationType.SP2:
        hybrid = [0, 1, 0]
    elif hyb == Chem.HybridizationType.SP3:
        hybrid = [0, 0, 1]
    else:
        hybrid = [0, 0, 1]  # Default to SP3 for SP3D, etc.
    # 3 dims

    # 5. Partial charge (1-dim continuous)
    if atom.HasProp('_GasteigerCharge'):
        partial_charge = [atom.GetDoubleProp('_GasteigerCharge')]
    else:
        partial_charge = [0.0]
    # 1 dim

    # Concatenate: 10 + 1 + 1 + 3 + 1 = 16 dims
    features = np.concatenate([
        atom_type,      # 10
        aromatic,       # 1
        in_ring,        # 1
        hybrid,         # 3
        partial_charge  # 1
    ])

    assert len(features) == 16, f"Feature length mismatch: {len(features)}"

    return features

def one_hot(value, choices):
    """One-hot encoding"""
    encoding = [0] * len(choices)
    if value in choices:
        encoding[choices.index(value)] = 1
    return encoding
```

#### „Ç®„ÉÉ„Ç∏ÁâπÂæ¥ÈáèÔºà3Ê¨°ÂÖÉÔºâ- ÊúÄÂ∞èÊßãÊàê

**Ë®≠Ë®àÊñπÈáù**: BDE + ÁµêÂêàÊÉÖÂ†±„ÅÆÊúÄÂ∞è„Çª„ÉÉ„Éà

| „Ç´„ÉÜ„Ç¥„É™ | Ê¨°ÂÖÉ | ÂÜÖÂÆπ | ÁêÜÁî± |
|---------|------|------|------|
| **BDEÔºàÊúÄÈáçË¶ÅÔºâ** | 1 | Bond Dissociation Energy from BonDNet (normalized) | „Éï„É©„Ç∞„É°„É≥„ÉÜ„Éº„Ç∑„Éß„É≥Á¢∫Áéá„ÅÆ‰∏ªË¶ÅÂõ†Â≠ê |
| **ÁµêÂêàÊ¨°Êï∞** | 1 | Bond order (1.0, 2.0, 3.0, 1.5 for aromatic) | ÁµêÂêà„ÅÆÂº∑„Åï |
| **Áí∞ÂÜÖÁµêÂêà** | 1 | Binary (in ring/not in ring) | Áí∞„ÅÆÂÆâÂÆöÊÄß |
| **ÂêàË®à** | **3** | - | **‰∫àÂÇô„Å™„Åó** |

**ÂâäÈô§„Åï„Çå„ÅüÁâπÂæ¥Ôºàv4.1„Å´„ÅÇ„Å£„Åü„ÇÇ„ÅÆÔºâ**:
- ÁµêÂêàÊ¨°Êï∞one-hotÔºà4Ê¨°ÂÖÉÔºâ ‚Üí ÈÄ£Á∂öÂÄ§1Ê¨°ÂÖÉ„Åß‰ª£Êõø
- ÂÖ±ÂΩπÔºà1Ê¨°ÂÖÉÔºâ ‚Üí Ëä≥È¶ôÊóèÊÄß„ÉªÁí∞ÊßãÈÄ†„Åã„ÇâÊé®Ê∏¨ÂèØËÉΩ
- Á´ã‰ΩìÂåñÂ≠¶Ôºà3Ê¨°ÂÖÉÔºâ ‚Üí EI-MS„Åß„ÅØ„ÅÇ„Åæ„ÇäÈáçË¶Å„Åß„Å™„ÅÑ
- ÂõûËª¢ÂèØËÉΩÊÄßÔºà1Ê¨°ÂÖÉÔºâ ‚Üí „Éï„É©„Ç∞„É°„É≥„ÉÜ„Éº„Ç∑„Éß„É≥„Å∏„ÅÆÂΩ±ÈüøÂ∞è
- ÁµêÂêàË∑ùÈõ¢Ôºà1Ê¨°ÂÖÉÔºâ ‚Üí ÁµêÂêàÊ¨°Êï∞„Å®Áõ∏Èñ¢

**ÂÆüË£Ö‰æã**:
```python
def get_bond_features_minimal(bond: Chem.Bond, bde_value: float) -> np.ndarray:
    """
    Extract 3-dimensional minimal bond features
    """

    # 1. BDE (normalized, 1-dim)
    bde_normalized = normalize_bde(bde_value)  # [0, 1] range

    # 2. Bond order (continuous, 1-dim)
    bond_type = bond.GetBondType()
    if bond_type == Chem.BondType.SINGLE:
        bond_order = 1.0
    elif bond_type == Chem.BondType.DOUBLE:
        bond_order = 2.0
    elif bond_type == Chem.BondType.TRIPLE:
        bond_order = 3.0
    elif bond_type == Chem.BondType.AROMATIC:
        bond_order = 1.5
    else:
        bond_order = 1.0  # Default

    # 3. In ring (binary, 1-dim)
    in_ring = float(bond.IsInRing())

    # Concatenate: 1 + 1 + 1 = 3 dims
    features = np.array([bde_normalized, bond_order, in_ring])

    assert len(features) == 3, f"Feature length mismatch: {len(features)}"

    return features

def normalize_bde(bde_kcal_mol: float) -> float:
    """Normalize BDE to [0, 1] range"""
    return (bde_kcal_mol - 50.0) / 150.0  # 50-200 kcal/mol range
```

---

## Phase 0: BDE-db2Áí∞Â¢ÉÊßãÁØâ

Ôºàv4.1„Å®Âêå„ÅòÂÜÖÂÆπ - Â§âÊõ¥„Å™„ÅóÔºâ

---

## Phase 1: „Éá„Éº„ÇøÊ∫ñÂÇô

### 1.1 NIST 17„Éá„Éº„ÇøË™≠„ÅøËæº„Åø

Ôºàv4.1„Å®Âêå„ÅòÂÜÖÂÆπ - Â§âÊõ¥„Å™„ÅóÔºâ

### 1.2 „Éá„Éº„Çø„Éï„Ç£„É´„Çø„É™„É≥„Ç∞

Ôºàv4.1„Å®Âêå„ÅòÂÜÖÂÆπ - Â§âÊõ¥„Å™„ÅóÔºâ

### 1.3 BDEÂâçË®àÁÆóÔºàBonDNet BDE-db2Ôºâ

Ôºàv4.1„Å®Âêå„ÅòÂÜÖÂÆπ - Â§âÊõ¥„Å™„ÅóÔºâ

### 1.4 PyG GraphÁîüÊàêÔºàÊúÄÂ∞èÊßãÊàêÁâàÔºâ

```python
# src/data/graph_generator.py
"""
PyTorch Geometric Graph Generator (Minimal Configuration)
"""

import torch
from torch_geometric.data import Data
from rdkit import Chem
from rdkit.Chem import AllChem
import numpy as np
from typing import Dict, List
import h5py

class GraphGeneratorMinimal:
    """Generate PyTorch Geometric graphs with minimal features (16 node, 3 edge)"""

    def __init__(self, bde_cache_path: str = "data/processed/bde_cache.h5"):
        self.bde_cache = h5py.File(bde_cache_path, 'r')

    def smiles_to_graph(
        self,
        smiles: str,
        spectrum: np.ndarray,
        molecule_idx: int
    ) -> Data:
        """
        Convert SMILES to PyG Data object with minimal features

        Args:
            smiles: SMILES string
            spectrum: Target spectrum [1000]
            molecule_idx: Index for BDE cache lookup

        Returns:
            PyG Data object with 16-dim nodes and 3-dim edges
        """
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            return None

        # Add hydrogens for complete graph
        mol = Chem.AddHs(mol)

        # Compute Gasteiger charges (needed for partial charge feature)
        AllChem.ComputeGasteigerCharges(mol)

        # Get BDE values from cache
        bde_dict = {}
        if str(molecule_idx) in self.bde_cache:
            grp = self.bde_cache[str(molecule_idx)]
            for bond_idx in grp.keys():
                bde_dict[int(bond_idx)] = float(grp[bond_idx][()])

        # Node features (16 dims per atom)
        node_features = []
        for atom in mol.GetAtoms():
            node_features.append(get_atom_features_minimal(atom))

        x = torch.tensor(node_features, dtype=torch.float)

        # Edge features (3 dims per bond)
        edge_index = []
        edge_attr = []

        for bond in mol.GetBonds():
            i = bond.GetBeginAtomIdx()
            j = bond.GetEndAtomIdx()
            bond_idx = bond.GetIdx()

            # Get BDE value
            bde_value = bde_dict.get(bond_idx, 100.0)  # Default if not in cache

            # Bidirectional edges
            edge_index.append([i, j])
            edge_index.append([j, i])

            bond_features = get_bond_features_minimal(bond, bde_value)
            edge_attr.append(bond_features)
            edge_attr.append(bond_features)  # Same features for both directions

        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
        edge_attr = torch.tensor(edge_attr, dtype=torch.float)

        # Target spectrum
        y = torch.tensor(spectrum, dtype=torch.float)

        # Create PyG Data
        data = Data(
            x=x,
            edge_index=edge_index,
            edge_attr=edge_attr,
            y=y,
            smiles=smiles
        )

        return data
```

---

## Phase 2: GNNÂ≠¶Áøí

### 2.1 Â≠¶Áøí„Çπ„ÇØ„É™„Éó„ÉàÔºàÊúÄÂ∞èÊßãÊàêÁâàÔºâ

```python
# scripts/train_gnn_minimal.py
"""
Train QC-GN2oEI model (Minimal Configuration)
"""

import torch
import torch.nn as nn
from torch_geometric.loader import DataLoader
from src.models.qcgn2oei_minimal import QCGN2oEI_Minimal
import wandb
import yaml
from pathlib import Path
from tqdm import tqdm

def cosine_similarity_loss(pred, target):
    """Cosine Similarity Loss (same as QC-GN2oMS2)"""
    pred_norm = pred / (pred.norm(dim=1, keepdim=True) + 1e-8)
    target_norm = target / (target.norm(dim=1, keepdim=True) + 1e-8)
    cosine_sim = (pred_norm * target_norm).sum(dim=1)
    return (1 - cosine_sim).mean()

def train_qcgn2oei_minimal(config_path: str = "config/training_minimal.yml"):
    """Train QC-GN2oEI model with minimal features"""

    # Load config
    with open(config_path) as f:
        config = yaml.safe_load(f)

    # Initialize wandb
    wandb.init(project="qcgn2oei-minimal", config=config)

    # Device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    # Data loaders
    train_data = torch.load("data/processed/nist17_train.pt")
    val_data = torch.load("data/processed/nist17_val.pt")

    train_loader = DataLoader(
        train_data,
        batch_size=config['training']['batch_size'],
        shuffle=True,
        num_workers=4
    )

    val_loader = DataLoader(
        val_data,
        batch_size=config['training']['batch_size'],
        shuffle=False,
        num_workers=4
    )

    # Model (minimal configuration)
    model = QCGN2oEI_Minimal(
        node_dim=16,      # Minimal
        edge_dim=3,       # Minimal
        hidden_dim=config['model']['hidden_dim'],
        num_layers=config['model']['num_layers'],
        num_heads=config['model']['num_heads'],
        output_dim=config['model']['output_dim'],
        dropout=config['model']['dropout']
    ).to(device)

    print(f"Model parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")
    print(f"Node features: 16 dims (minimal)")
    print(f"Edge features: 3 dims (minimal)")

    # Optimizer (RAdam from QC-GN2oMS2)
    optimizer = torch.optim.RAdam(
        model.parameters(),
        lr=config['training']['learning_rate'],
        weight_decay=config['training']['weight_decay']
    )

    # Learning rate scheduler
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=config['training']['num_epochs'],
        eta_min=1e-6
    )

    # Training loop
    best_val_loss = float('inf')

    for epoch in range(config['training']['num_epochs']):
        # Train
        model.train()
        train_loss = 0.0

        for batch in tqdm(train_loader, desc=f"Epoch {epoch+1} [Train]"):
            batch = batch.to(device)

            optimizer.zero_grad()
            pred = model(batch)
            loss = cosine_similarity_loss(pred, batch.y)
            loss.backward()
            optimizer.step()

            train_loss += loss.item()

        train_loss /= len(train_loader)

        # Validation
        model.eval()
        val_loss = 0.0

        with torch.no_grad():
            for batch in tqdm(val_loader, desc=f"Epoch {epoch+1} [Val]"):
                batch = batch.to(device)
                pred = model(batch)
                loss = cosine_similarity_loss(pred, batch.y)
                val_loss += loss.item()

        val_loss /= len(val_loader)

        # Scheduler step
        scheduler.step()

        # Logging
        wandb.log({
            'epoch': epoch,
            'train_loss': train_loss,
            'val_loss': val_loss,
            'learning_rate': optimizer.param_groups[0]['lr']
        })

        print(f"Epoch {epoch+1}/{config['training']['num_epochs']}: "
              f"Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}")

        # Save best model
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': val_loss,
            }, "models/qcgn2oei_minimal_best.pth")
            print(f"‚úÖ Best model saved (Val Loss: {val_loss:.4f})")

    print(f"Training complete. Best Val Loss: {best_val_loss:.4f}")

if __name__ == "__main__":
    train_qcgn2oei_minimal()
```

### 2.2 Ë®≠ÂÆö„Éï„Ç°„Ç§„É´ÔºàÊúÄÂ∞èÊßãÊàêÁâàÔºâ

```yaml
# config/training_minimal.yml

model:
  node_dim: 16      # Minimal (QC-GN2oMS2-inspired)
  edge_dim: 3       # Minimal (BDE + bond order + in ring)
  hidden_dim: 256
  num_layers: 10
  num_heads: 8
  output_dim: 1000
  dropout: 0.1

training:
  num_epochs: 300
  batch_size: 32
  learning_rate: 0.001
  weight_decay: 1e-5
  early_stopping_patience: 50

data:
  bde_cache: "data/processed/bde_cache.h5"
  train_data: "data/processed/nist17_train.pt"
  val_data: "data/processed/nist17_val.pt"
  test_data: "data/processed/nist17_test.pt"
```

### 2.3 Â≠¶ÁøíÊôÇÈñìË¶ãÁ©ç„ÇÇ„ÇäÔºàÈ´òÈÄüÂåñÔºâ

**„Éë„É©„É°„Éº„ÇøÊï∞„ÅÆÊØîËºÉ**:

| È†ÖÁõÆ | v4.1 (128/64) | v4.2 (16/3) | ÂâäÊ∏õÁéá |
|------|--------------|------------|--------|
| Node encoder | 128√ó256 = 32,768 | 16√ó256 = 4,096 | **-87.5%** |
| Edge encoder | 64√ó256 = 16,384 | 3√ó256 = 768 | **-95.3%** |
| EncoderÂêàË®à | 49,152 | 4,864 | **-90.1%** |

**1„Ç®„Éù„ÉÉ„ÇØ„ÅÆÊôÇÈñìÔºàÊé®ÂÆöÔºâ**:
```
224,000 samples (train) √∑ 32 batch_size = 7,000 iterations
7,000 iterations √ó 0.7 sec/iter = 4,900 sec = 1.36 hours
Ôºàv4.1: 1.56ÊôÇÈñì ‚Üí v4.2: 1.36ÊôÇÈñì„ÄÅÁ¥Ñ13%È´òÈÄüÂåñÔºâ
```

**ÂêàË®àÂ≠¶ÁøíÊôÇÈñìÔºàÊé®ÂÆöÔºâ**:
```
300 epochs √ó 1.36 hours = 408 hours
‚Üí early stopping„ÅßÁ¥Ñ40ÊôÇÈñìÔºà30„Ç®„Éù„ÉÉ„ÇØÁ®ãÂ∫¶„ÅßÂèéÊùüÊÉ≥ÂÆöÔºâ
Ôºàv4.1: 48ÊôÇÈñì ‚Üí v4.2: 40ÊôÇÈñì„ÄÅÁ¥Ñ17%È´òÈÄüÂåñÔºâ
```

---

## Phase 3: Ë©ï‰æ°„Å®ÂèçÂæ©ÊîπÂñÑÂà§Êñ≠

### 3.1 Ë©ï‰æ°„É°„Éà„É™„ÇØ„Çπ

```python
# scripts/evaluate_minimal.py
"""
Comprehensive evaluation for minimal configuration model
"""

import torch
import numpy as np
from torch_geometric.loader import DataLoader
from src.models.qcgn2oei_minimal import QCGN2oEI_Minimal
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

def cosine_similarity_metric(pred, target):
    """Calculate cosine similarity"""
    pred_norm = pred / (np.linalg.norm(pred, axis=1, keepdims=True) + 1e-8)
    target_norm = target / (np.linalg.norm(target, axis=1, keepdims=True) + 1e-8)
    return (pred_norm * target_norm).sum(axis=1).mean()

def top_k_recall(pred, target, k=10):
    """Top-K Recall"""
    recalls = []
    for p, t in zip(pred, target):
        true_top_k = set(np.argsort(t)[-k:])
        pred_top_k = set(np.argsort(p)[-k:])
        recall = len(true_top_k & pred_top_k) / k
        recalls.append(recall)
    return np.mean(recalls)

def evaluate_model(
    model_path: str = "models/qcgn2oei_minimal_best.pth",
    test_data_path: str = "data/processed/nist17_test.pt"
):
    """Comprehensive model evaluation"""

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # Load model
    checkpoint = torch.load(model_path)
    model = QCGN2oEI_Minimal(
        node_dim=16,
        edge_dim=3,
        hidden_dim=256,
        num_layers=10,
        num_heads=8,
        output_dim=1000,
        dropout=0.1
    )
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()

    # Load test data
    test_data = torch.load(test_data_path)
    test_loader = DataLoader(test_data, batch_size=32, shuffle=False)

    # Inference
    all_predictions = []
    all_targets = []

    with torch.no_grad():
        for batch in test_loader:
            batch = batch.to(device)
            pred = model(batch)
            all_predictions.append(pred.cpu().numpy())
            all_targets.append(batch.y.cpu().numpy())

    predictions = np.concatenate(all_predictions, axis=0)
    targets = np.concatenate(all_targets, axis=0)

    # Metrics
    cosine_sim = cosine_similarity_metric(predictions, targets)
    top5_recall = top_k_recall(predictions, targets, k=5)
    top10_recall = top_k_recall(predictions, targets, k=10)
    top20_recall = top_k_recall(predictions, targets, k=20)

    mse = mean_squared_error(targets.flatten(), predictions.flatten())
    rmse = np.sqrt(mse)

    print("=" * 60)
    print("QC-GN2oEI Minimal Configuration Evaluation")
    print("=" * 60)
    print(f"Node features: 16 dims")
    print(f"Edge features: 3 dims")
    print("-" * 60)
    print(f"Cosine Similarity: {cosine_sim:.4f}")
    print(f"Top-5 Recall:      {top5_recall:.4f}")
    print(f"Top-10 Recall:     {top10_recall:.4f}")
    print(f"Top-20 Recall:     {top20_recall:.4f}")
    print(f"MSE:               {mse:.6f}")
    print(f"RMSE:              {rmse:.6f}")
    print("=" * 60)

    # Decision logic
    print("\n" + "=" * 60)
    print("Performance Assessment")
    print("=" * 60)

    if cosine_sim >= 0.85:
        print("‚úÖ EXCELLENT: Cosine Similarity >= 0.85")
        print("   Recommendation: Adopt v4.2 minimal configuration!")
        print("   No feature expansion needed.")
    elif cosine_sim >= 0.80:
        print("‚ö†Ô∏è  GOOD: Cosine Similarity 0.80-0.85")
        print("   Recommendation: Consider minor feature additions")
        print("   Proceed to Phase 4 for targeted feature expansion")
    else:
        print("‚ùå INSUFFICIENT: Cosine Similarity < 0.80")
        print("   Recommendation: Feature expansion required")
        print("   Proceed to Phase 4 for systematic feature addition")

    return {
        'cosine_similarity': cosine_sim,
        'top5_recall': top5_recall,
        'top10_recall': top10_recall,
        'top20_recall': top20_recall,
        'mse': mse,
        'rmse': rmse
    }

if __name__ == "__main__":
    results = evaluate_model()
```

### 3.2 Âà§ÂÆöÂü∫Ê∫ñ„Å®„Ç¢„ÇØ„Ç∑„Éß„É≥„Éó„É©„É≥

| Cosine Similarity | Âà§ÂÆö | „Ç¢„ÇØ„Ç∑„Éß„É≥ |
|------------------|------|-----------|
| **‚â• 0.85** | ‚úÖ ÂÑ™ÁßÄ | **v4.2Êé°Áî®ÂÆå‰∫ÜÔºÅ** ÁâπÂæ¥ÈáèÊã°Âºµ‰∏çË¶Å |
| **0.80 - 0.85** | ‚ö†Ô∏è ËâØÂ•Ω | ËªΩÂæÆ„Å™ÊîπÂñÑÊ§úË®é ‚Üí Phase 4„Å∏ |
| **0.75 - 0.80** | ‚ö†Ô∏è Ë¶ÅÊîπÂñÑ | ÁâπÂæ¥ÈáèËøΩÂä†ÂøÖÈ†à ‚Üí Phase 4„Å∏ |
| **< 0.75** | ‚ùå ‰∏çÂçÅÂàÜ | ‰∏≠ÈñìÊßãÊàê(64/32)Ê§úË®é ‚Üí Phase 4„Å∏ |

---

## Phase 4: ÁâπÂæ¥ÈáèÊã°ÂºµÔºàÊù°‰ª∂‰ªò„ÅçÔºâ

### 4.1 ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶ÂàÜÊûê

**Phase 3„ÅßCosine Sim < 0.85„ÅÆÂ†¥Âêà„ÅÆ„ÅøÂÆüÊñΩ**

```python
# scripts/analyze_feature_importance.py
"""
Analyze which features should be added next
"""

import torch
from src.models.qcgn2oei_minimal import QCGN2oEI_Minimal
import numpy as np

def analyze_attention_weights(
    model_path: str = "models/qcgn2oei_minimal_best.pth"
):
    """
    Analyze GATv2 attention weights to understand feature importance
    """

    # Load model
    model = QCGN2oEI_Minimal(...)
    checkpoint = torch.load(model_path)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()

    # Hook to capture attention weights
    attention_weights = []

    def hook_fn(module, input, output):
        # GATv2Conv returns (output, attention_weights)
        if isinstance(output, tuple):
            attention_weights.append(output[1].detach().cpu().numpy())

    # Register hooks
    for layer in model.gat_layers:
        layer.register_forward_hook(hook_fn)

    # Run inference on validation set
    # ... (collect attention weights)

    # Analyze patterns
    print("Attention Weight Analysis")
    print("=" * 60)
    # TODO: Implement analysis

    return attention_weights

def propose_feature_additions(cosine_sim: float):
    """
    Propose which features to add based on performance
    """

    print("\n" + "=" * 60)
    print("Feature Addition Recommendations")
    print("=" * 60)

    if cosine_sim >= 0.80 and cosine_sim < 0.85:
        print("Performance: GOOD (0.80-0.85)")
        print("\nRecommended additions (Priority 1):")
        print("  1. Formal charge (3 dims) - for ionic fragments")
        print("  2. Degree (6 dims) - for branching patterns")
        print("Total: +9 dims ‚Üí 16+9 = 25 node dims")

    elif cosine_sim >= 0.75 and cosine_sim < 0.80:
        print("Performance: MODERATE (0.75-0.80)")
        print("\nRecommended additions (Priority 1+2):")
        print("  Priority 1:")
        print("    - Formal charge (3 dims)")
        print("    - Degree (6 dims)")
        print("  Priority 2:")
        print("    - Hydrogen count (5 dims)")
        print("    - Conjugated bonds (1 edge dim)")
        print("Total: +14 node dims, +1 edge dim")
        print("  ‚Üí 16+14 = 30 node dims, 3+1 = 4 edge dims")

    else:  # < 0.75
        print("Performance: INSUFFICIENT (<0.75)")
        print("\nRecommended: Move to intermediate configuration")
        print("  Node: 64 dims (41 used + 23 reserved)")
        print("  Edge: 32 dims (12 used + 20 reserved)")
        print("  See v4.3 specification for details")

if __name__ == "__main__":
    # Run after Phase 3 evaluation
    results = evaluate_model()
    cosine_sim = results['cosine_similarity']

    analyze_attention_weights()
    propose_feature_additions(cosine_sim)
```

### 4.2 ÊÆµÈöéÁöÑÊã°Âºµ„Éï„É≠„Éº„ÉÅ„É£„Éº„Éà

```
Phase 3Ë©ï‰æ°ÁµêÊûú
     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Cosine Similarity = ?                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚Üì
     ‚îú‚îÄ ‚â• 0.85 ‚Üí ‚úÖ ÂÆå‰∫ÜÔºÅv4.2Êé°Áî®
     ‚îÇ
     ‚îú‚îÄ 0.80-0.85 ‚Üí v4.3 (ËªΩÂæÆÊã°Âºµ)
     ‚îÇ                ‚îú‚îÄ „Éé„Éº„Éâ: 16 ‚Üí 25 (+9)
     ‚îÇ                ‚îî‚îÄ ÂÜçË©ï‰æ° ‚Üí ÂÆå‰∫Ü or „Åï„Çâ„Å´Êã°Âºµ
     ‚îÇ
     ‚îú‚îÄ 0.75-0.80 ‚Üí v4.3 (‰∏≠Â∫¶Êã°Âºµ)
     ‚îÇ                ‚îú‚îÄ „Éé„Éº„Éâ: 16 ‚Üí 30 (+14)
     ‚îÇ                ‚îú‚îÄ „Ç®„ÉÉ„Ç∏: 3 ‚Üí 4 (+1)
     ‚îÇ                ‚îî‚îÄ ÂÜçË©ï‰æ° ‚Üí ÂÆå‰∫Ü or „Åï„Çâ„Å´Êã°Âºµ
     ‚îÇ
     ‚îî‚îÄ < 0.75 ‚Üí v4.3 (‰∏≠ÈñìÊßãÊàê)
                    ‚îú‚îÄ „Éé„Éº„Éâ: 16 ‚Üí 64 (+48)
                    ‚îú‚îÄ „Ç®„ÉÉ„Ç∏: 3 ‚Üí 32 (+29)
                    ‚îî‚îÄ ÂÜçË©ï‰æ°
```

---

## Ë®≠ÂÆö„Éï„Ç°„Ç§„É´Ë©≥Á¥∞

### config.ymlÔºà„É°„Ç§„É≥Ë®≠ÂÆö„ÄÅv4.2ÊúÄÂ∞èÊßãÊàêÁâàÔºâ

```yaml
# config.yml - Main Configuration (v4.2 Minimal)

project:
  name: "QC-GN2oEI"
  version: "2.2-minimal"
  description: "Minimal configuration approach with iterative refinement"
  design_philosophy: "Start simple, iterate based on evidence"

# BDE Configuration
bde:
  backend: "bondnet"
  bondnet:
    model_type: "bde-db2"
    model_path: "models/bondnet_bde_db2_best.pth"
    dataset_path: "data/external/bde-db2"
    device: "cuda"
    batch_size: 256

# Data paths
data:
  nist17_path: "data/external/nist17/mainlib"
  bde_cache: "data/processed/bde_cache.h5"
  train_data: "data/processed/nist17_train.pt"
  val_data: "data/processed/nist17_val.pt"
  test_data: "data/processed/nist17_test.pt"

  # Data filtering
  filtering:
    supported_elements: ['C', 'H', 'O', 'N', 'F', 'S', 'P', 'Cl', 'Br', 'I']
    min_molecular_weight: 50.0
    max_molecular_weight: 1000.0
    validate_smiles: true

# Model architecture (MINIMAL CONFIGURATION)
model:
  type: "QCGN2oEI_Minimal"

  # Minimal feature dimensions (QC-GN2oMS2-inspired)
  node_dim: 16   # No reserved dims
  edge_dim: 3    # No reserved dims

  # GNN layers
  hidden_dim: 256
  num_layers: 10
  num_heads: 8

  # Output
  output_dim: 1000

  # Regularization
  dropout: 0.1

  # Advanced features
  use_residual: true
  use_edge_features: true
  global_pooling: "mean"

# Training
training:
  num_epochs: 300
  batch_size: 32
  learning_rate: 0.001
  weight_decay: 1e-5

  optimizer: "RAdam"
  scheduler: "CosineAnnealingLR"
  scheduler_params:
    T_max: 300
    eta_min: 1e-6

  loss: "cosine_similarity"
  early_stopping_patience: 50

  checkpoint_dir: "checkpoints"
  save_every: 10

# Evaluation & Iteration
evaluation:
  metrics:
    - "cosine_similarity"
    - "top_k_recall"
    - "mse"
    - "rmse"

  top_k_values: [5, 10, 20, 50]

  # Performance thresholds for iteration decision
  performance_thresholds:
    excellent: 0.85      # No feature expansion needed
    good: 0.80           # Minor additions considered
    moderate: 0.75       # Feature additions recommended
    insufficient: 0.0    # Significant expansion required

  # Feature expansion plan (conditional)
  feature_expansion:
    enabled: true
    analyze_attention: true
    ablation_study: true

# Hardware
hardware:
  device: "cuda"
  gpu_id: 0
  num_workers: 4
  pin_memory: true
  use_amp: true
  amp_dtype: "float16"

# Logging
logging:
  use_wandb: true
  wandb_project: "qcgn2oei-minimal"
  wandb_entity: null
  log_every: 10
  save_predictions: true

# Reproducibility
seed: 42
deterministic: true
```

---

## ÈñãÁô∫Áí∞Â¢ÉÊßãÁØâ

Ôºàv4.1„Å®Âêå„ÅòÂÜÖÂÆπ - Â§âÊõ¥„Å™„ÅóÔºâ

---

## „Çø„Ç§„É†„É©„Ç§„É≥

### ÂÖ®‰Ωì„Çπ„Ç±„Ç∏„É•„Éº„É´Ôºàv4.2Êõ¥Êñ∞ÁâàÔºâ

| „Éï„Çß„Éº„Ç∫ | „Çø„Çπ„ÇØ | Êé®ÂÆöÊôÇÈñì | Á¥ØÁ©çÊôÇÈñì |
|---------|--------|---------|---------|
| **Phase 0** | BDE-db2„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ | 30ÂàÜ | 30ÂàÜ |
| **Phase 0** | „Éá„Éº„ÇøÂâçÂá¶ÁêÜ | 3ÊôÇÈñì | 3.5ÊôÇÈñì |
| **Phase 0** | BonDNetÂÜçÂ≠¶Áøí | 48-72ÊôÇÈñì | 51.5-75.5ÊôÇÈñì |
| **Phase 0** | „É¢„Éá„É´Ê§úË®º | 1ÊôÇÈñì | 52.5-76.5ÊôÇÈñì |
| **Phase 1** | NISTË™≠„ÅøËæº„Åø | 30ÂàÜ | 53-77ÊôÇÈñì |
| **Phase 1** | „Éá„Éº„Çø„Éï„Ç£„É´„Çø„É™„É≥„Ç∞ | 10ÂàÜ | 53.17-77.17ÊôÇÈñì |
| **Phase 1** | BDEË®àÁÆóÔºà280KÔºâ | 70ÂàÜ | 54.33-78.33ÊôÇÈñì |
| **Phase 1** | PyG GraphÁîüÊàêÔºà16/3Ê¨°ÂÖÉÔºâ | 60ÂàÜ | 55.33-79.33ÊôÇÈñì |
| **Phase 2** | GNNÂ≠¶ÁøíÔºàÊúÄÂ∞èÊßãÊàêÔºâ | **40ÊôÇÈñì** | **95.33-119.33ÊôÇÈñì** |
| **Phase 3** | Ë©ï‰æ°„ÉªÂà§ÂÆö | 2ÊôÇÈñì | 97.33-121.33ÊôÇÈñì |
| **Phase 4** | ÁâπÂæ¥ÈáèÊã°ÂºµÔºàÊù°‰ª∂‰ªò„ÅçÔºâ | 0-24ÊôÇÈñì | 97.33-145.33ÊôÇÈñì |
| **ÂêàË®à** | - | **97-145ÊôÇÈñì** | **4.0-6.0Êó•** |

**v4.2„Åß„ÅÆÂ§âÊõ¥**:
- GNNÂ≠¶ÁøíÊôÇÈñì: 48ÊôÇÈñì ‚Üí 40ÊôÇÈñìÔºà-17%„ÄÅÈ´òÈÄüÂåñÔºâ
- Phase 4ËøΩÂä†ÔºàÊù°‰ª∂‰ªò„ÅçÔºâ: ÊÄßËÉΩ‰∏çË∂≥ÊôÇ„ÅÆ„ÅøÂÆüÊñΩ

---

## ÂèÇËÄÉÊñáÁåÆ

Ôºàv4.1„Å®Âêå„ÅòÂÜÖÂÆπ - Â§âÊõ¥„Å™„ÅóÔºâ

---

## „Åæ„Å®„ÇÅ

### v4.2„ÅÆ‰∏ªË¶Å„Å™ÊîπÂñÑÁÇπ

1. **ÊúÄÂ∞èÊßãÊàê„Ç¢„Éó„É≠„Éº„ÉÅ**: QC-GN2oMS2„ÅÆÂÆüË®ºÊ∏à„ÅøË®≠Ë®à„Å´Ê∫ñÊã†
2. **„É°„É¢„É™ÂäπÁéá**: v4.1ÊØî„Åß88%ÂâäÊ∏õÔºà1.3GB ‚Üí 0.16GBÔºâ
3. **Â≠¶ÁøíÈ´òÈÄüÂåñ**: v4.1ÊØî„Åß17%È´òÈÄüÂåñÔºà48ÊôÇÈñì ‚Üí 40ÊôÇÈñìÔºâ
4. **ÂèçÂæ©ÊîπÂñÑÊà¶Áï•**: ÊÄßËÉΩË©ï‰æ° ‚Üí ÂøÖË¶Å„Å´Âøú„Åò„Å¶ÊÆµÈöéÁöÑÊã°Âºµ
5. **ÂÆüË®º‰∏ªÁæ©**: "Start simple, iterate based on evidence"

### ÊúüÂæÖ„Åï„Çå„ÇãÊàêÊûú

**„Éô„Çπ„Éà„Ç±„Éº„ÇπÔºàCosine Sim ‚â• 0.85Ôºâ**:
- ‚úÖ v4.2Êé°Áî®ÂÆå‰∫ÜÔºàÊúÄÂ∞èÊßãÊàê„ÅßÂçÅÂàÜÔºâ
- „É°„É¢„É™ÂäπÁéá„ÉªÂ≠¶ÁøíÈÄüÂ∫¶„ÅÆÂ§ßÂπÖÊîπÂñÑ
- QC-GN2oMS2„ÅÆÊàêÂäü„ÇíÂÜçÁèæ

**‰∏≠Èñì„Ç±„Éº„ÇπÔºàCosine Sim 0.80-0.85Ôºâ**:
- v4.3„ÅßËªΩÂæÆ„Å™ÁâπÂæ¥ËøΩÂä†Ôºà+9-14Ê¨°ÂÖÉÔºâ
- ÂêàÁêÜÁöÑ„Å™„Éà„É¨„Éº„Éâ„Ç™„Éï

**ÊúÄÊÇ™„Ç±„Éº„ÇπÔºàCosine Sim < 0.75Ôºâ**:
- ‰∏≠ÈñìÊßãÊàêÔºà64/32Ê¨°ÂÖÉÔºâ„Å´Êã°Âºµ
- „Åù„Çå„Åß„ÇÇv4.1„Çà„ÇäÂäπÁéáÁöÑ

---

**Document Version**: 4.2
**Last Updated**: 2025-12-02
**Status**: Ready for Implementation (Minimal Configuration with Iterative Refinement)
**Design Philosophy**: Start Simple, Iterate Based on Evidence
